{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimplySnap/PDLP-AMD-RIPS/blob/connorphillips700-patch-1/PDHG_torch_pulp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5be116d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from time import perf_counter\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "torch.set_num_threads(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2dcf794",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mps_to_standard_form_torch(mps_file, device='cpu'):\n",
        "    \"\"\"\n",
        "    Parses an MPS file and returns the standard form LP components as PyTorch tensors:\n",
        "        minimize     cᵀx\n",
        "        subject to   G x ≥ h\n",
        "                     A x = b\n",
        "                     l ≤ x ≤ u\n",
        "\n",
        "    Returns: c, G, h, A, b, l, u\n",
        "    \"\"\"\n",
        "    \n",
        "    #Read MPS file\n",
        "    with open(mps_file, 'r') as f:\n",
        "        lines = [line.strip() for line in f if line.strip() and not line.startswith('*')]\n",
        "\n",
        "    section = None\n",
        "    row_types = {}\n",
        "    row_indices = {}\n",
        "    col_data = defaultdict(list)\n",
        "    rhs_data = {}\n",
        "    range_data = {}\n",
        "    bound_data = defaultdict(dict)\n",
        "\n",
        "    row_counter = 0\n",
        "    var_names = set()\n",
        "    obj_row_name = None\n",
        "\n",
        "    for line in lines:\n",
        "        \n",
        "        if line == 'NAME' or line == 'ENDATA':\n",
        "            continue\n",
        "        elif line == 'ROWS':\n",
        "            section = 'ROWS'\n",
        "            continue\n",
        "        elif line == 'COLUMNS':\n",
        "            section = 'COLUMNS'\n",
        "            continue\n",
        "        elif line == 'RHS':\n",
        "            section = 'RHS'\n",
        "            continue\n",
        "        elif line == 'RANGES':\n",
        "            section = 'RANGES'\n",
        "            continue\n",
        "        elif line == 'BOUNDS':\n",
        "            section = 'BOUNDS'\n",
        "            continue\n",
        "    \n",
        "        tokens = line.split()\n",
        "        if section == 'ROWS':\n",
        "            sense, row_name = tokens\n",
        "            row_types[row_name] = sense\n",
        "            row_indices[row_name] = row_counter\n",
        "            if sense == 'N':\n",
        "                obj_row_name = row_name\n",
        "            row_counter += 1\n",
        "\n",
        "        elif section == 'COLUMNS':\n",
        "            var_name = tokens[0]\n",
        "            var_names.add(var_name)\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                col_data[var_name].append((row, val))\n",
        "\n",
        "        elif section == 'RHS':\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                rhs_data[row] = val\n",
        "\n",
        "        elif section == 'RANGES':\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                range_data[row] = val\n",
        "\n",
        "        elif section == 'BOUNDS':\n",
        "            bound_type, _, var_name = tokens[:3]\n",
        "            val = float(tokens[3]) if len(tokens) > 3 else None\n",
        "            if bound_type == 'LO':\n",
        "                bound_data[var_name]['lo'] = val\n",
        "            elif bound_type == 'UP':\n",
        "                bound_data[var_name]['up'] = val\n",
        "            elif bound_type == 'FX':\n",
        "                bound_data[var_name]['lo'] = val\n",
        "                bound_data[var_name]['up'] = val\n",
        "            elif bound_type == 'FR':\n",
        "                # bound_data[var_name]['lo'] = -float('inf')\n",
        "                bound_data[var_name]['lo'] = 0.0\n",
        "                bound_data[var_name]['up'] = float('inf')\n",
        "                \n",
        "    # Check correct information loaded\n",
        "    # print(row_types, col_data,rhs_data,range_data,bound_data)\n",
        "    \n",
        "    # Final variable ordering and index mapping\n",
        "    var_names = sorted(var_names)\n",
        "    var_index = {v: i for i, v in enumerate(var_names)}\n",
        "    num_vars = len(var_names)\n",
        "\n",
        "    # Build objective vector c\n",
        "    c = np.zeros(num_vars)\n",
        "    for var, entries in col_data.items():\n",
        "        col_idx = var_index[var]\n",
        "        for row_name, val in entries:\n",
        "            if row_name == obj_row_name:\n",
        "                c[col_idx] = val\n",
        "\n",
        "    # Build row vectors from col_data\n",
        "    row_vectors = {row: np.zeros(num_vars) for row in row_types}\n",
        "    for var, entries in col_data.items():\n",
        "        col_idx = var_index[var]\n",
        "        for row_name, val in entries:\n",
        "            row_vectors[row_name][col_idx] = val\n",
        "\n",
        "    # Build A (equality) and G (inequality)\n",
        "    A_rows, b_eq = [], []\n",
        "    G_rows, h_ineq = [], []\n",
        "\n",
        "    for row_name, sense in row_types.items():\n",
        "        if row_name == obj_row_name:\n",
        "            continue\n",
        "\n",
        "        row_vec = row_vectors[row_name]\n",
        "        rhs_val = rhs_data.get(row_name, 0.0)\n",
        "        range_val = range_data.get(row_name, None)\n",
        "\n",
        "        if range_val is not None:\n",
        "            # Ranged constraint → convert to two inequalities\n",
        "            if sense == 'G':\n",
        "                lb = rhs_val\n",
        "                ub = rhs_val + abs(range_val)\n",
        "            elif sense == 'L':\n",
        "                ub = rhs_val\n",
        "                lb = rhs_val - abs(range_val)\n",
        "            elif sense == 'E':\n",
        "                if range_val > 0:\n",
        "                    lb = rhs_val\n",
        "                    ub = rhs_val + range_val\n",
        "                else:\n",
        "                    ub = rhs_val\n",
        "                    lb = rhs_val + range_val\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported ranged sense: {sense}\")\n",
        "\n",
        "            G_rows.append(row_vec)\n",
        "            h_ineq.append(lb)\n",
        "\n",
        "            G_rows.append(-row_vec)\n",
        "            h_ineq.append(-ub)\n",
        "\n",
        "        else:\n",
        "            if sense == 'E':\n",
        "                A_rows.append(row_vec)\n",
        "                b_eq.append(rhs_val)\n",
        "            elif sense == 'G':\n",
        "                G_rows.append(row_vec)\n",
        "                h_ineq.append(rhs_val)\n",
        "            elif sense == 'L':\n",
        "                G_rows.append(-row_vec)\n",
        "                h_ineq.append(-rhs_val)\n",
        "\n",
        "    # Bounds\n",
        "    l = []\n",
        "    u = []\n",
        "    for var in var_names:\n",
        "        # lo = bound_data[var].get('lo', -float('inf'))\n",
        "        lo = bound_data[var].get('lo', 0)\n",
        "        up = bound_data[var].get('up', float('inf'))\n",
        "        l.append(lo)\n",
        "        u.append(up)\n",
        "\n",
        "    # Convert all to torch\n",
        "    A_tensor = torch.tensor(np.array(A_rows), dtype=torch.float32, device=device) \n",
        "    b_tensor = torch.tensor(np.array(b_eq), dtype=torch.float32, device=device).view(-1, 1) \n",
        "\n",
        "    G_tensor = torch.tensor(np.array(G_rows), dtype=torch.float32, device=device) \n",
        "    h_tensor = torch.tensor(np.array(h_ineq), dtype=torch.float32, device=device).view(-1, 1) \n",
        "\n",
        "    c_tensor = torch.tensor(c, dtype=torch.float32, device=device).view(-1, 1)\n",
        "\n",
        "    l_tensor = torch.tensor(l, dtype=torch.float32, device=device).view(-1, 1)\n",
        "    u_tensor = torch.tensor(u, dtype=torch.float32, device=device).view(-1, 1)\n",
        "\n",
        "    return c_tensor, G_tensor, h_tensor, A_tensor, b_tensor, l_tensor, u_tensor\n",
        "\n",
        "def project_lambda_box(grad, is_neg_inf, is_pos_inf):\n",
        "    \"\"\"\n",
        "    Projects the gradient onto the normal cone of the feasible region defined by bounds l and u.\n",
        "\n",
        "    For each i:\n",
        "      - If l[i] == -inf and u[i] == +inf: projection is 0\n",
        "      - If l[i] == -inf and u[i] is real: clamp to ≤ 0 (R⁻)\n",
        "      - If l[i] is real and u[i] == +inf: clamp to ≥ 0 (R⁺)\n",
        "      - If both are finite: no projection (keep full value)\n",
        "\n",
        "    Args:\n",
        "        grad: (n, 1) gradient vector (torch tensor)\n",
        "        l: (n, 1) lower bounds (torch tensor)\n",
        "        u: (n, 1) upper bounds (torch tensor)\n",
        "\n",
        "    Returns:\n",
        "        projected: (n, 1) projected gradient (interpreted as λ)\n",
        "    \"\"\"\n",
        "    projected = torch.zeros_like(grad)\n",
        "\n",
        "    # Case 1: (-inf, +inf) → {0}\n",
        "    unconstrained = is_neg_inf & is_pos_inf\n",
        "    projected[unconstrained] = 0.0\n",
        "\n",
        "    # Case 2: (-inf, real) → R⁻ → clamp at 0 from above\n",
        "    neg_only = is_neg_inf & ~is_pos_inf\n",
        "    projected[neg_only] = torch.clamp(grad[neg_only], max=0.0)\n",
        "\n",
        "    # Case 3: (real, +inf) → R⁺ → clamp at 0 from below\n",
        "    pos_only = ~is_neg_inf & is_pos_inf\n",
        "    projected[pos_only] = torch.clamp(grad[pos_only], min=0.0)\n",
        "\n",
        "    # Case 4: (real, real) → full space → keep gradient\n",
        "    fully_bounded = ~is_neg_inf & ~is_pos_inf\n",
        "    projected[fully_bounded] = grad[fully_bounded]\n",
        "\n",
        "    return projected\n",
        "\n",
        "\n",
        "def spectral_norm_estimate_torch(A, num_iters=10):\n",
        "  \"\"\"\n",
        "  Estimates the spectral norm of a matrix A with enough acuracy to use in\n",
        "  setting the step size of the PDHG algorithm.\n",
        "  \"\"\"\n",
        "\n",
        "  b = torch.randn(A.shape[1], 1, device=A.device)\n",
        "  for _ in range(num_iters):\n",
        "      b = A.T @ (A @ b)\n",
        "      b /= torch.norm(b)\n",
        "  return torch.norm(A @ b)\n",
        "\n",
        "def pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf, l_dual, u_dual, device, max_iter=100000, tol=1e-2, verbose=True, term_period=1000):\n",
        "    \"\"\"\n",
        "    Solves:\n",
        "        min cᵀx s.t. Gx ≥ h, Ax = b, l ≤ x ≤ u\n",
        "    using the Primal-Dual Hybrid Gradient (PDHG) algorithm.\n",
        "\n",
        "    Args:\n",
        "      c, G, h, A, b, l, u: torch tensors representing the problem data\n",
        "      is_pos_inf: torch tensor indicating which elements of u are +inf\n",
        "      is_neg_inf: torch tensor indicating which elements of l are -inf\n",
        "      l_dual: torch tensor representing the lower bounds of the dual variables\n",
        "      u_dual: torch tensor representing the upper bounds of the dual variables\n",
        "      device: torch device (cpu or cuda)\n",
        "      max_iter: maximum number of iterations\n",
        "      tol: tolerance for convergence\n",
        "      verbose: whether to print termination information\n",
        "      term_period: period for termination checks\n",
        "\n",
        "    Returns:\n",
        "      minimizer, objective value, and number of iterations for convergence\n",
        "    \"\"\"    \n",
        "    n = c.shape[0]\n",
        "    m_ineq = G.shape[0] if G.numel() > 0 else 0\n",
        "    m_eq = A.shape[0] if A.numel() > 0 else 0\n",
        "\n",
        "    # Combine constraints\n",
        "    combined_matrix_list = []\n",
        "    rhs = []\n",
        "    if m_ineq > 0:\n",
        "        combined_matrix_list.append(G)\n",
        "        rhs.append(h)\n",
        "    if m_eq > 0:\n",
        "        combined_matrix_list.append(A)\n",
        "        rhs.append(b)\n",
        "\n",
        "    if not combined_matrix_list:\n",
        "        raise ValueError(\"Both G and A matrices are empty.\")\n",
        "  \n",
        "    K = torch.vstack(combined_matrix_list).to(device)           # Combined constraint matrix\n",
        "    q = torch.vstack(rhs).to(device)                            # Combined right-hand side\n",
        "    c = c.to(device)\n",
        "  \n",
        "    q_norm = torch.linalg.norm(q, 2)\n",
        "    c_norm = torch.linalg.norm(c, 2)\n",
        "  \n",
        "    eta = 0.9 / spectral_norm_estimate_torch(K, num_iters=100)\n",
        "\n",
        "    if q_norm > 0 and c_norm > 0:\n",
        "        omega = torch.sqrt(c_norm / q_norm)\n",
        "    else:\n",
        "        omega = torch.tensor(1.0)\n",
        "\n",
        "    tau = eta / omega\n",
        "    sigma = eta * omega\n",
        "\n",
        "    theta = 1.0\n",
        "  \n",
        "    # Initialize primal and dual\n",
        "    x = torch.zeros((n, 1), device=device)\n",
        "    x_old = x.clone()\n",
        "    y = torch.zeros((K.shape[0], 1), device=device)\n",
        "  \n",
        "    for k in range(max_iter):\n",
        "        x_old.copy_(x)\n",
        "    \n",
        "        # Compute gradient and primal update\n",
        "        Kt_y = K.T @ y\n",
        "        grad = c - Kt_y\n",
        "        x = torch.clamp(x - tau * grad, min=l, max=u)\n",
        "\n",
        "        # Extrapolate\n",
        "        x_bar = x + theta * (x - x_old)\n",
        "\n",
        "        # Dual update\n",
        "        K_xbar = K @ x_bar\n",
        "        y += sigma * (q - K_xbar)\n",
        "\n",
        "        # Project duals:\n",
        "        if m_ineq > 0:\n",
        "            y[:m_ineq] = torch.clamp(y[:m_ineq], min=0.0)\n",
        "\n",
        "        # --- Check Termination Every term_period Iterations ---\n",
        "        if k % term_period == 0:\n",
        "            # Primal and dual objective\n",
        "            prim_obj = (c.T @ x)[0][0]\n",
        "            dual_obj = (q.T @ y)[0][0]\n",
        "\n",
        "            # Lagrange multipliers from box projection\n",
        "            lam = project_lambda_box(grad, is_neg_inf, is_pos_inf)\n",
        "            lam_pos = (l_dual.T @ torch.clamp(lam, min=0.0))[0][0]\n",
        "            lam_neg = (u_dual.T @ torch.clamp(lam, max=0.0))[0][0]\n",
        "\n",
        "            adjusted_dual = dual_obj + lam_pos + lam_neg\n",
        "            duality_gap = abs(adjusted_dual - prim_obj)\n",
        "\n",
        "            # Primal residual (feasibility)\n",
        "            residual_eq = A @ x - b if m_eq > 0 else torch.zeros(1, device=device)\n",
        "            residual_ineq = torch.clamp(h - G @ x, min=0.0) if m_ineq > 0 else torch.zeros(1, device=device)\n",
        "            primal_residual = torch.norm(torch.vstack([residual_eq, residual_ineq]), p=2).item()\n",
        "\n",
        "            # Dual residual (change in x)\n",
        "            dual_residual = torch.norm(grad - lam, p=2).item()\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"[{k}] Primal Obj: {prim_obj:.4f}, Adjusted Dual Obj: {adjusted_dual:.4f}, \"\n",
        "                      f\"Gap: {duality_gap:.2e}, Prim Res: {primal_residual:.2e}, Dual Res: {dual_residual:.2e}\")\n",
        "\n",
        "            # Termination condition\n",
        "            if (primal_residual <= tol * (1 + q_norm) and\n",
        "                dual_residual <= tol * (1 + c_norm) and\n",
        "                duality_gap <= tol * (1 + abs(prim_obj) + abs(adjusted_dual))):\n",
        "                if verbose:\n",
        "                    print(f\"Converged at iteration {k}\")\n",
        "                break\n",
        "            \n",
        "    return x, prim_obj.numpy(), k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cdbbc90a",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Timer:\n",
        "  \"\"\"\n",
        "  Timer class to measure execution time of code blocks.\n",
        "  Usage:\n",
        "  \n",
        "    with Timer(\"Label\"):\n",
        "        # Code block to be timed\n",
        "\n",
        "  Output:\n",
        "    Label: <time in seconds> seconds\n",
        "  \"\"\"\n",
        "    # ChatGPT wrote this and I don't know how it works\n",
        "  def __init__(self, label=\"Elapsed time\"):\n",
        "      self.label = label\n",
        "\n",
        "  def __enter__(self):\n",
        "      self.start = perf_counter()\n",
        "      return self\n",
        "\n",
        "  def __exit__(self, *args):\n",
        "      self.end = perf_counter()\n",
        "      self.elapsed = self.end - self.start\n",
        "      print(f\"{self.label}: {self.elapsed:.6f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af71d5fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "# --- Device Selection ---\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"PyTorch is using ROCm/CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"ROCm/CUDA not available. PyTorch is using CPU.\")\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "    mps_file_path = '25fv47.mps'\n",
        "\n",
        "\n",
        "# --- Data Loading ---\n",
        "    try:\n",
        "        c, G, h, A, b, l, u = mps_to_standard_form_torch(mps_file_path, device=device)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load MPS file: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    is_neg_inf = torch.isinf(l) & (l < 0)\n",
        "    is_pos_inf = torch.isinf(u) & (u > 0)\n",
        "\n",
        "    l_dual = l.clone()\n",
        "    u_dual = u.clone()\n",
        "\n",
        "    l_dual[is_neg_inf] = 0\n",
        "    u_dual[is_pos_inf] = 0\n",
        "    \n",
        "    with Timer():\n",
        "    # --- Run PDHG Solver on the GPU or CPU ---\n",
        "        _, obj, k = pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf, l_dual, u_dual, device=device, max_iter=100000, tol=1e-2, verbose=True, term_period=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1db85ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # --- Device Selection ---\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"PyTorch is using ROCm/CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"ROCm/CUDA not available. PyTorch is using CPU.\")\n",
        "\n",
        "    num_threads = torch.get_num_threads()\n",
        "    print(f\"PyTorch is running on {num_threads} threads.\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    mps_folder_path = 'feasible'\n",
        "    max_iter = 100000\n",
        "    tol = 1e-2\n",
        "    results = []\n",
        "\n",
        "    # --- Get all MPS files from the folder ---\n",
        "    mps_files = sorted([f for f in os.listdir(mps_folder_path) if f.endswith('.mps')])\n",
        "\n",
        "    for mps_file in mps_files:\n",
        "        mps_file_path = os.path.join(mps_folder_path, mps_file)\n",
        "        print(f\"\\nProcessing {mps_file_path}...\")\n",
        "\n",
        "        try:\n",
        "            # --- Load problem ---\n",
        "            c, G, h, A, b, l, u = mps_to_standard_form_torch(mps_file_path, device=device)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load MPS file: {mps_file_path}. Error: {e}\")\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': 'N/A',\n",
        "                'Iterations (k)': 'N/A',\n",
        "                'Time (s)': 'N/A',\n",
        "                'Status': f'Failed to load: {e}'\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        is_neg_inf = torch.isinf(l) & (l < 0)\n",
        "        is_pos_inf = torch.isinf(u) & (u > 0)\n",
        "\n",
        "        l_dual = l.clone()\n",
        "        u_dual = u.clone()\n",
        "        l_dual[is_neg_inf] = 0\n",
        "        u_dual[is_pos_inf] = 0\n",
        "\n",
        "        # --- Solve ---\n",
        "        try:\n",
        "            with Timer(\"Solve time\") as t:\n",
        "                x, obj, k = pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf,\n",
        "                                       l_dual, u_dual, device=device,\n",
        "                                       max_iter=max_iter, tol=tol, verbose=False)\n",
        "            time_elapsed = t.elapsed\n",
        "\n",
        "            status = \"Solved\"\n",
        "            if k == max_iter - 1:\n",
        "                status = \"Unsolved (max iterations reached)\"\n",
        "\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': obj,\n",
        "                'Iterations (k)': k,\n",
        "                'Time (s)': time_elapsed,\n",
        "                'Status': status\n",
        "            })\n",
        "\n",
        "            print(f\"Finished: {mps_file}, Time: {time_elapsed:.2f}s, Iter: {k}, Obj: {obj:.4f}, Status: {status}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Solver failed for {mps_file}. Error: {e}\")\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': 'N/A',\n",
        "                'Iterations (k)': 'N/A',\n",
        "                'Time (s)': 'N/A',\n",
        "                'Status': f'Solver failed: {e}'\n",
        "            })\n",
        "\n",
        "    # --- Save results to Excel ---\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_excel('pdhg_results.xlsx', index=False)\n",
        "    print(\"\\nAll done. Results saved to pdhg_results.xlsx.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cosc410",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
