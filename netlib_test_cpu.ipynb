{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimplySnap/PDLP-AMD-RIPS/blob/connorphillips700-patch-1/PDHG_torch_pulp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "5be116d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from time import perf_counter\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "torch.set_num_threads(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "c2dcf794",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mps_to_standard_form_torch(mps_file, device='cpu'):\n",
        "    \"\"\"\n",
        "    Parses an MPS file and returns the standard form LP components as PyTorch tensors:\n",
        "        minimize     cᵀx\n",
        "        subject to   G x ≥ h\n",
        "                     A x = b\n",
        "                     l ≤ x ≤ u\n",
        "\n",
        "    Returns: c, G, h, A, b, l, u\n",
        "    \"\"\"\n",
        "    \n",
        "    #Read MPS file\n",
        "    with open(mps_file, 'r') as f:\n",
        "        lines = [line.strip() for line in f if line.strip() and not line.startswith('*')]\n",
        "\n",
        "    section = None\n",
        "    row_types = {}\n",
        "    row_indices = {}\n",
        "    col_data = defaultdict(list)\n",
        "    rhs_data = {}\n",
        "    range_data = {}\n",
        "    bound_data = defaultdict(dict)\n",
        "\n",
        "    row_counter = 0\n",
        "    var_names = set()\n",
        "    obj_row_name = None\n",
        "\n",
        "    for line in lines:\n",
        "        \n",
        "        if line == 'NAME' or line == 'ENDATA':\n",
        "            continue\n",
        "        elif line == 'ROWS':\n",
        "            section = 'ROWS'\n",
        "            continue\n",
        "        elif line == 'COLUMNS':\n",
        "            section = 'COLUMNS'\n",
        "            continue\n",
        "        elif line == 'RHS':\n",
        "            section = 'RHS'\n",
        "            continue\n",
        "        elif line == 'RANGES':\n",
        "            section = 'RANGES'\n",
        "            continue\n",
        "        elif line == 'BOUNDS':\n",
        "            section = 'BOUNDS'\n",
        "            continue\n",
        "    \n",
        "        tokens = line.split()\n",
        "        if section == 'ROWS':\n",
        "            sense, row_name = tokens\n",
        "            row_types[row_name] = sense\n",
        "            row_indices[row_name] = row_counter\n",
        "            if sense == 'N':\n",
        "                obj_row_name = row_name\n",
        "            row_counter += 1\n",
        "\n",
        "        elif section == 'COLUMNS':\n",
        "            var_name = tokens[0]\n",
        "            var_names.add(var_name)\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                col_data[var_name].append((row, val))\n",
        "\n",
        "        elif section == 'RHS':\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                rhs_data[row] = val\n",
        "\n",
        "        elif section == 'RANGES':\n",
        "            for i in range(1, len(tokens), 2):\n",
        "                row, val = tokens[i], float(tokens[i + 1])\n",
        "                range_data[row] = val\n",
        "\n",
        "        elif section == 'BOUNDS':\n",
        "            bound_type, _, var_name = tokens[:3]\n",
        "            val = float(tokens[3]) if len(tokens) > 3 else None\n",
        "            if bound_type == 'LO':\n",
        "                bound_data[var_name]['lo'] = val\n",
        "            elif bound_type == 'UP':\n",
        "                bound_data[var_name]['up'] = val\n",
        "            elif bound_type == 'FX':\n",
        "                bound_data[var_name]['lo'] = val\n",
        "                bound_data[var_name]['up'] = val\n",
        "            elif bound_type == 'FR':\n",
        "                # bound_data[var_name]['lo'] = -float('inf')\n",
        "                bound_data[var_name]['lo'] = 0.0\n",
        "                bound_data[var_name]['up'] = float('inf')\n",
        "                \n",
        "    # Check correct information loaded\n",
        "    # print(row_types, col_data,rhs_data,range_data,bound_data)\n",
        "    \n",
        "    # Final variable ordering and index mapping\n",
        "    var_names = sorted(var_names)\n",
        "    var_index = {v: i for i, v in enumerate(var_names)}\n",
        "    num_vars = len(var_names)\n",
        "\n",
        "    # Build objective vector c\n",
        "    c = np.zeros(num_vars)\n",
        "    for var, entries in col_data.items():\n",
        "        col_idx = var_index[var]\n",
        "        for row_name, val in entries:\n",
        "            if row_name == obj_row_name:\n",
        "                c[col_idx] = val\n",
        "\n",
        "    # Build row vectors from col_data\n",
        "    row_vectors = {row: np.zeros(num_vars) for row in row_types}\n",
        "    for var, entries in col_data.items():\n",
        "        col_idx = var_index[var]\n",
        "        for row_name, val in entries:\n",
        "            row_vectors[row_name][col_idx] = val\n",
        "\n",
        "    # Build A (equality) and G (inequality)\n",
        "    A_rows, b_eq = [], []\n",
        "    G_rows, h_ineq = [], []\n",
        "\n",
        "    for row_name, sense in row_types.items():\n",
        "        if row_name == obj_row_name:\n",
        "            continue\n",
        "\n",
        "        row_vec = row_vectors[row_name]\n",
        "        rhs_val = rhs_data.get(row_name, 0.0)\n",
        "        range_val = range_data.get(row_name, None)\n",
        "\n",
        "        if range_val is not None:\n",
        "            # Ranged constraint → convert to two inequalities\n",
        "            if sense == 'G':\n",
        "                lb = rhs_val\n",
        "                ub = rhs_val + abs(range_val)\n",
        "            elif sense == 'L':\n",
        "                ub = rhs_val\n",
        "                lb = rhs_val - abs(range_val)\n",
        "            elif sense == 'E':\n",
        "                if range_val > 0:\n",
        "                    lb = rhs_val\n",
        "                    ub = rhs_val + range_val\n",
        "                else:\n",
        "                    ub = rhs_val\n",
        "                    lb = rhs_val + range_val\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported ranged sense: {sense}\")\n",
        "\n",
        "            G_rows.append(row_vec)\n",
        "            h_ineq.append(lb)\n",
        "\n",
        "            G_rows.append(-row_vec)\n",
        "            h_ineq.append(-ub)\n",
        "\n",
        "        else:\n",
        "            if sense == 'E':\n",
        "                A_rows.append(row_vec)\n",
        "                b_eq.append(rhs_val)\n",
        "            elif sense == 'G':\n",
        "                G_rows.append(row_vec)\n",
        "                h_ineq.append(rhs_val)\n",
        "            elif sense == 'L':\n",
        "                G_rows.append(-row_vec)\n",
        "                h_ineq.append(-rhs_val)\n",
        "\n",
        "    # Bounds\n",
        "    l = []\n",
        "    u = []\n",
        "    for var in var_names:\n",
        "        # lo = bound_data[var].get('lo', -float('inf'))\n",
        "        lo = bound_data[var].get('lo', 0)\n",
        "        up = bound_data[var].get('up', float('inf'))\n",
        "        l.append(lo)\n",
        "        u.append(up)\n",
        "\n",
        "    # Convert all to torch\n",
        "    A_tensor = torch.tensor(np.array(A_rows), dtype=torch.float32, device=device) \n",
        "    b_tensor = torch.tensor(np.array(b_eq), dtype=torch.float32, device=device).view(-1, 1) \n",
        "\n",
        "    G_tensor = torch.tensor(np.array(G_rows), dtype=torch.float32, device=device) \n",
        "    h_tensor = torch.tensor(np.array(h_ineq), dtype=torch.float32, device=device).view(-1, 1) \n",
        "\n",
        "    c_tensor = torch.tensor(c, dtype=torch.float32, device=device).view(-1, 1)\n",
        "\n",
        "    l_tensor = torch.tensor(l, dtype=torch.float32, device=device).view(-1, 1)\n",
        "    u_tensor = torch.tensor(u, dtype=torch.float32, device=device).view(-1, 1)\n",
        "\n",
        "    return c_tensor, G_tensor, h_tensor, A_tensor, b_tensor, l_tensor, u_tensor\n",
        "\n",
        "def project_lambda_box(grad, is_neg_inf, is_pos_inf):\n",
        "    \"\"\"\n",
        "    Projects the gradient onto the normal cone of the feasible region defined by bounds l and u.\n",
        "\n",
        "    For each i:\n",
        "      - If l[i] == -inf and u[i] == +inf: projection is 0\n",
        "      - If l[i] == -inf and u[i] is real: clamp to ≤ 0 (R⁻)\n",
        "      - If l[i] is real and u[i] == +inf: clamp to ≥ 0 (R⁺)\n",
        "      - If both are finite: no projection (keep full value)\n",
        "\n",
        "    Args:\n",
        "        grad: (n, 1) gradient vector (torch tensor)\n",
        "        l: (n, 1) lower bounds (torch tensor)\n",
        "        u: (n, 1) upper bounds (torch tensor)\n",
        "\n",
        "    Returns:\n",
        "        projected: (n, 1) projected gradient (interpreted as λ)\n",
        "    \"\"\"\n",
        "    projected = torch.zeros_like(grad)\n",
        "\n",
        "    # Case 1: (-inf, +inf) → {0}\n",
        "    unconstrained = is_neg_inf & is_pos_inf\n",
        "    projected[unconstrained] = 0.0\n",
        "\n",
        "    # Case 2: (-inf, real) → R⁻ → clamp at 0 from above\n",
        "    neg_only = is_neg_inf & ~is_pos_inf\n",
        "    projected[neg_only] = torch.clamp(grad[neg_only], max=0.0)\n",
        "\n",
        "    # Case 3: (real, +inf) → R⁺ → clamp at 0 from below\n",
        "    pos_only = ~is_neg_inf & is_pos_inf\n",
        "    projected[pos_only] = torch.clamp(grad[pos_only], min=0.0)\n",
        "\n",
        "    # Case 4: (real, real) → full space → keep gradient\n",
        "    fully_bounded = ~is_neg_inf & ~is_pos_inf\n",
        "    projected[fully_bounded] = grad[fully_bounded]\n",
        "\n",
        "    return projected\n",
        "\n",
        "\n",
        "def spectral_norm_estimate_torch(A, num_iters=10):\n",
        "  \"\"\"\n",
        "  Estimates the spectral norm of a matrix A with enough acuracy to use in\n",
        "  setting the step size of the PDHG algorithm.\n",
        "  \"\"\"\n",
        "\n",
        "  b = torch.randn(A.shape[1], 1, device=A.device)\n",
        "  for _ in range(num_iters):\n",
        "      b = A.T @ (A @ b)\n",
        "      b /= torch.norm(b)\n",
        "  return torch.norm(A @ b)\n",
        "\n",
        "def pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf, l_dual, u_dual, device, max_iter=100000, tol=1e-2, verbose=True, term_period=1000):\n",
        "    \"\"\"\n",
        "    Solves:\n",
        "        min cᵀx s.t. Gx ≥ h, Ax = b, l ≤ x ≤ u\n",
        "    using the Primal-Dual Hybrid Gradient (PDHG) algorithm.\n",
        "\n",
        "    Args:\n",
        "      c, G, h, A, b, l, u: torch tensors representing the problem data\n",
        "      is_pos_inf: torch tensor indicating which elements of u are +inf\n",
        "      is_neg_inf: torch tensor indicating which elements of l are -inf\n",
        "      l_dual: torch tensor representing the lower bounds of the dual variables\n",
        "      u_dual: torch tensor representing the upper bounds of the dual variables\n",
        "      device: torch device (cpu or cuda)\n",
        "      max_iter: maximum number of iterations\n",
        "      tol: tolerance for convergence\n",
        "      verbose: whether to print termination information\n",
        "      term_period: period for termination checks\n",
        "\n",
        "    Returns:\n",
        "      minimizer, objective value, and number of iterations for convergence\n",
        "    \"\"\"    \n",
        "    n = c.shape[0]\n",
        "    m_ineq = G.shape[0] if G.numel() > 0 else 0\n",
        "    m_eq = A.shape[0] if A.numel() > 0 else 0\n",
        "\n",
        "    # Combine constraints\n",
        "    combined_matrix_list = []\n",
        "    rhs = []\n",
        "    if m_ineq > 0:\n",
        "        combined_matrix_list.append(G)\n",
        "        rhs.append(h)\n",
        "    if m_eq > 0:\n",
        "        combined_matrix_list.append(A)\n",
        "        rhs.append(b)\n",
        "\n",
        "    if not combined_matrix_list:\n",
        "        raise ValueError(\"Both G and A matrices are empty.\")\n",
        "  \n",
        "    K = torch.vstack(combined_matrix_list).to(device)           # Combined constraint matrix\n",
        "    q = torch.vstack(rhs).to(device)                            # Combined right-hand side\n",
        "    c = c.to(device)\n",
        "  \n",
        "    q_norm = torch.linalg.norm(q, 2)\n",
        "    c_norm = torch.linalg.norm(c, 2)\n",
        "  \n",
        "    eta = 0.9 / spectral_norm_estimate_torch(K, num_iters=100)\n",
        "\n",
        "    if q_norm > 0 and c_norm > 0:\n",
        "        omega = torch.sqrt(c_norm / q_norm)\n",
        "    else:\n",
        "        omega = torch.tensor(1.0)\n",
        "\n",
        "    tau = eta / omega\n",
        "    sigma = eta * omega\n",
        "\n",
        "    theta = 1.0\n",
        "  \n",
        "    # Initialize primal and dual\n",
        "    x = torch.zeros((n, 1), device=device)\n",
        "    x_old = x.clone()\n",
        "    y = torch.zeros((K.shape[0], 1), device=device)\n",
        "  \n",
        "    for k in range(max_iter):\n",
        "        x_old.copy_(x)\n",
        "    \n",
        "        # Compute gradient and primal update\n",
        "        Kt_y = K.T @ y\n",
        "        grad = c - Kt_y\n",
        "        x = torch.clamp(x - tau * grad, min=l, max=u)\n",
        "\n",
        "        # Extrapolate\n",
        "        x_bar = x + theta * (x - x_old)\n",
        "\n",
        "        # Dual update\n",
        "        K_xbar = K @ x_bar\n",
        "        y += sigma * (q - K_xbar)\n",
        "\n",
        "        # Project duals:\n",
        "        if m_ineq > 0:\n",
        "            y[:m_ineq] = torch.clamp(y[:m_ineq], min=0.0)\n",
        "\n",
        "        # --- Check Termination Every term_period Iterations ---\n",
        "        if k % term_period == 0:\n",
        "            # Primal and dual objective\n",
        "            prim_obj = (c.T @ x)[0][0]\n",
        "            dual_obj = (q.T @ y)[0][0]\n",
        "\n",
        "            # Lagrange multipliers from box projection\n",
        "            lam = project_lambda_box(grad, is_neg_inf, is_pos_inf)\n",
        "            lam_pos = (l_dual.T @ torch.clamp(lam, min=0.0))[0][0]\n",
        "            lam_neg = (u_dual.T @ torch.clamp(lam, max=0.0))[0][0]\n",
        "\n",
        "            adjusted_dual = dual_obj + lam_pos + lam_neg\n",
        "            duality_gap = abs(adjusted_dual - prim_obj)\n",
        "\n",
        "            # Primal residual (feasibility)\n",
        "            residual_eq = A @ x - b if m_eq > 0 else torch.zeros(1, device=device)\n",
        "            residual_ineq = torch.clamp(h - G @ x, min=0.0) if m_ineq > 0 else torch.zeros(1, device=device)\n",
        "            primal_residual = torch.norm(torch.vstack([residual_eq, residual_ineq]), p=2).item()\n",
        "\n",
        "            # Dual residual (change in x)\n",
        "            dual_residual = torch.norm(grad - lam, p=2).item()\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"[{k}] Primal Obj: {prim_obj:.4f}, Adjusted Dual Obj: {adjusted_dual:.4f}, \"\n",
        "                      f\"Gap: {duality_gap:.2e}, Prim Res: {primal_residual:.2e}, Dual Res: {dual_residual:.2e}\")\n",
        "\n",
        "            # Termination condition\n",
        "            if (primal_residual <= tol * (1 + q_norm) and\n",
        "                dual_residual <= tol * (1 + c_norm) and\n",
        "                duality_gap <= tol * (1 + abs(prim_obj) + abs(adjusted_dual))):\n",
        "                if verbose:\n",
        "                    print(f\"Converged at iteration {k}\")\n",
        "                break\n",
        "            \n",
        "    return x, prim_obj.numpy(), k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "cdbbc90a",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Timer:\n",
        "  \"\"\"\n",
        "  Timer class to measure execution time of code blocks.\n",
        "  Usage:\n",
        "  \n",
        "    with Timer(\"Label\"):\n",
        "        # Code block to be timed\n",
        "\n",
        "  Output:\n",
        "    Label: <time in seconds> seconds\n",
        "  \"\"\"\n",
        "    # ChatGPT wrote this and I don't know how it works\n",
        "  def __init__(self, label=\"Elapsed time\"):\n",
        "      self.label = label\n",
        "\n",
        "  def __enter__(self):\n",
        "      self.start = perf_counter()\n",
        "      return self\n",
        "\n",
        "  def __exit__(self, *args):\n",
        "      self.end = perf_counter()\n",
        "      self.elapsed = self.end - self.start\n",
        "      print(f\"{self.label}: {self.elapsed:.6f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "af71d5fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROCm/CUDA not available. PyTorch is using CPU.\n",
            "[0] Primal Obj: -9.4309, Adjusted Dual Obj: 333.4697, Gap: 3.43e+02, Prim Res: 9.40e+02, Dual Res: 2.90e+01\n",
            "[1000] Primal Obj: -151.3803, Adjusted Dual Obj: 72789.7734, Gap: 7.29e+04, Prim Res: 6.18e+02, Dual Res: 9.67e+01\n",
            "[2000] Primal Obj: 487.7855, Adjusted Dual Obj: 30446.7969, Gap: 3.00e+04, Prim Res: 4.40e+02, Dual Res: 7.02e+01\n",
            "[3000] Primal Obj: 2300.2920, Adjusted Dual Obj: 53744.4219, Gap: 5.14e+04, Prim Res: 4.60e+02, Dual Res: 6.08e+01\n",
            "[4000] Primal Obj: 3859.4238, Adjusted Dual Obj: 66047.6484, Gap: 6.22e+04, Prim Res: 5.11e+02, Dual Res: 6.38e+01\n",
            "[5000] Primal Obj: 4674.2017, Adjusted Dual Obj: 35504.3789, Gap: 3.08e+04, Prim Res: 4.75e+02, Dual Res: 5.37e+01\n",
            "[6000] Primal Obj: 4812.3960, Adjusted Dual Obj: 30465.2324, Gap: 2.57e+04, Prim Res: 3.21e+02, Dual Res: 6.43e+01\n",
            "[7000] Primal Obj: 5260.2471, Adjusted Dual Obj: 31778.6816, Gap: 2.65e+04, Prim Res: 2.67e+02, Dual Res: 6.23e+01\n",
            "[8000] Primal Obj: 6400.3882, Adjusted Dual Obj: 18138.2891, Gap: 1.17e+04, Prim Res: 3.27e+02, Dual Res: 3.49e+01\n",
            "[9000] Primal Obj: 7161.6064, Adjusted Dual Obj: 7077.7129, Gap: 8.39e+01, Prim Res: 3.11e+02, Dual Res: 2.48e+01\n",
            "[10000] Primal Obj: 8526.9199, Adjusted Dual Obj: 14597.4609, Gap: 6.07e+03, Prim Res: 2.22e+02, Dual Res: 2.99e+01\n",
            "[11000] Primal Obj: 9743.0078, Adjusted Dual Obj: 5460.4805, Gap: 4.28e+03, Prim Res: 1.68e+02, Dual Res: 2.38e+01\n",
            "[12000] Primal Obj: 10479.0469, Adjusted Dual Obj: 5800.5596, Gap: 4.68e+03, Prim Res: 2.03e+02, Dual Res: 1.97e+01\n",
            "[13000] Primal Obj: 10502.0088, Adjusted Dual Obj: 9671.5508, Gap: 8.30e+02, Prim Res: 2.29e+02, Dual Res: 1.90e+01\n",
            "[14000] Primal Obj: 10474.0195, Adjusted Dual Obj: 10446.7842, Gap: 2.72e+01, Prim Res: 1.94e+02, Dual Res: 2.40e+01\n",
            "[15000] Primal Obj: 10006.9502, Adjusted Dual Obj: 13489.4229, Gap: 3.48e+03, Prim Res: 1.18e+02, Dual Res: 3.29e+01\n",
            "[16000] Primal Obj: 9617.5244, Adjusted Dual Obj: 15692.5010, Gap: 6.07e+03, Prim Res: 1.20e+02, Dual Res: 3.18e+01\n",
            "[17000] Primal Obj: 9338.3848, Adjusted Dual Obj: 11791.7627, Gap: 2.45e+03, Prim Res: 1.78e+02, Dual Res: 1.91e+01\n",
            "[18000] Primal Obj: 9236.1621, Adjusted Dual Obj: 7985.7393, Gap: 1.25e+03, Prim Res: 1.86e+02, Dual Res: 1.26e+01\n",
            "[19000] Primal Obj: 9254.7773, Adjusted Dual Obj: 6258.1025, Gap: 3.00e+03, Prim Res: 1.36e+02, Dual Res: 1.30e+01\n",
            "[20000] Primal Obj: 9416.8418, Adjusted Dual Obj: 1395.6743, Gap: 8.02e+03, Prim Res: 7.51e+01, Dual Res: 1.35e+01\n",
            "[21000] Primal Obj: 9330.0107, Adjusted Dual Obj: 3032.0317, Gap: 6.30e+03, Prim Res: 1.19e+02, Dual Res: 1.17e+01\n",
            "[22000] Primal Obj: 9214.6260, Adjusted Dual Obj: 5554.9146, Gap: 3.66e+03, Prim Res: 1.60e+02, Dual Res: 1.04e+01\n",
            "[23000] Primal Obj: 8792.2090, Adjusted Dual Obj: 9586.0469, Gap: 7.94e+02, Prim Res: 1.50e+02, Dual Res: 1.39e+01\n",
            "[24000] Primal Obj: 8731.6221, Adjusted Dual Obj: 13571.7354, Gap: 4.84e+03, Prim Res: 8.74e+01, Dual Res: 2.44e+01\n",
            "[25000] Primal Obj: 8565.3467, Adjusted Dual Obj: 12335.3984, Gap: 3.77e+03, Prim Res: 7.12e+01, Dual Res: 2.50e+01\n",
            "[26000] Primal Obj: 8168.1416, Adjusted Dual Obj: 7694.2661, Gap: 4.74e+02, Prim Res: 1.25e+02, Dual Res: 1.57e+01\n",
            "[27000] Primal Obj: 7962.3350, Adjusted Dual Obj: 5285.1084, Gap: 2.68e+03, Prim Res: 1.44e+02, Dual Res: 7.12e+00\n",
            "[28000] Primal Obj: 7582.6343, Adjusted Dual Obj: 1038.7100, Gap: 6.54e+03, Prim Res: 1.10e+02, Dual Res: 8.19e+00\n",
            "[29000] Primal Obj: 7244.4995, Adjusted Dual Obj: 1045.4668, Gap: 6.20e+03, Prim Res: 5.59e+01, Dual Res: 9.76e+00\n",
            "[30000] Primal Obj: 6837.5801, Adjusted Dual Obj: 2623.1377, Gap: 4.21e+03, Prim Res: 7.88e+01, Dual Res: 9.00e+00\n",
            "[31000] Primal Obj: 6449.9243, Adjusted Dual Obj: 4441.5405, Gap: 2.01e+03, Prim Res: 1.22e+02, Dual Res: 7.50e+00\n",
            "[32000] Primal Obj: 6065.9717, Adjusted Dual Obj: 7267.9482, Gap: 1.20e+03, Prim Res: 1.21e+02, Dual Res: 8.96e+00\n",
            "[33000] Primal Obj: 5807.3320, Adjusted Dual Obj: 8120.0566, Gap: 2.31e+03, Prim Res: 7.37e+01, Dual Res: 1.79e+01\n",
            "[34000] Primal Obj: 5667.6450, Adjusted Dual Obj: 8108.1357, Gap: 2.44e+03, Prim Res: 4.31e+01, Dual Res: 1.97e+01\n",
            "[35000] Primal Obj: 5622.6675, Adjusted Dual Obj: 6501.9375, Gap: 8.79e+02, Prim Res: 8.45e+01, Dual Res: 1.41e+01\n",
            "[36000] Primal Obj: 5627.0825, Adjusted Dual Obj: 6059.4136, Gap: 4.32e+02, Prim Res: 1.10e+02, Dual Res: 5.43e+00\n",
            "[37000] Primal Obj: 5631.2197, Adjusted Dual Obj: 4084.9436, Gap: 1.55e+03, Prim Res: 9.22e+01, Dual Res: 5.45e+00\n",
            "[38000] Primal Obj: 5609.3018, Adjusted Dual Obj: 3830.6094, Gap: 1.78e+03, Prim Res: 4.77e+01, Dual Res: 7.28e+00\n",
            "[39000] Primal Obj: 5622.2773, Adjusted Dual Obj: 3663.9136, Gap: 1.96e+03, Prim Res: 4.59e+01, Dual Res: 7.92e+00\n",
            "[40000] Primal Obj: 5532.1636, Adjusted Dual Obj: 3576.2349, Gap: 1.96e+03, Prim Res: 8.03e+01, Dual Res: 5.72e+00\n",
            "[41000] Primal Obj: 5438.9858, Adjusted Dual Obj: 5170.5645, Gap: 2.68e+02, Prim Res: 8.86e+01, Dual Res: 4.13e+00\n",
            "[42000] Primal Obj: 5444.5605, Adjusted Dual Obj: 7082.0981, Gap: 1.64e+03, Prim Res: 6.65e+01, Dual Res: 1.05e+01\n",
            "[43000] Primal Obj: 5395.6216, Adjusted Dual Obj: 8748.5605, Gap: 3.35e+03, Prim Res: 3.61e+01, Dual Res: 1.39e+01\n",
            "[44000] Primal Obj: 5401.2471, Adjusted Dual Obj: 8336.5117, Gap: 2.94e+03, Prim Res: 4.92e+01, Dual Res: 1.18e+01\n",
            "[45000] Primal Obj: 5379.8755, Adjusted Dual Obj: 7760.7798, Gap: 2.38e+03, Prim Res: 7.41e+01, Dual Res: 5.76e+00\n",
            "[46000] Primal Obj: 5430.7046, Adjusted Dual Obj: 4881.2617, Gap: 5.49e+02, Prim Res: 7.17e+01, Dual Res: 3.74e+00\n",
            "[47000] Primal Obj: 5476.5327, Adjusted Dual Obj: 3922.2388, Gap: 1.55e+03, Prim Res: 4.22e+01, Dual Res: 4.89e+00\n",
            "[48000] Primal Obj: 5567.5137, Adjusted Dual Obj: 3570.4014, Gap: 2.00e+03, Prim Res: 2.46e+01, Dual Res: 5.47e+00\n",
            "[49000] Primal Obj: 5677.3682, Adjusted Dual Obj: 4967.5811, Gap: 7.10e+02, Prim Res: 5.13e+01, Dual Res: 4.83e+00\n",
            "[50000] Primal Obj: 5797.6138, Adjusted Dual Obj: 6812.1641, Gap: 1.01e+03, Prim Res: 6.48e+01, Dual Res: 3.88e+00\n",
            "[51000] Primal Obj: 5933.4546, Adjusted Dual Obj: 8383.3721, Gap: 2.45e+03, Prim Res: 5.39e+01, Dual Res: 6.80e+00\n",
            "[52000] Primal Obj: 6064.6338, Adjusted Dual Obj: 8280.9033, Gap: 2.22e+03, Prim Res: 2.95e+01, Dual Res: 9.88e+00\n",
            "[53000] Primal Obj: 6130.2661, Adjusted Dual Obj: 7820.1318, Gap: 1.69e+03, Prim Res: 2.92e+01, Dual Res: 9.27e+00\n",
            "[54000] Primal Obj: 6164.6641, Adjusted Dual Obj: 6679.5347, Gap: 5.15e+02, Prim Res: 5.07e+01, Dual Res: 5.24e+00\n",
            "[55000] Primal Obj: 6203.8486, Adjusted Dual Obj: 5802.4604, Gap: 4.01e+02, Prim Res: 5.59e+01, Dual Res: 2.62e+00\n",
            "[56000] Primal Obj: 6155.0518, Adjusted Dual Obj: 5567.7544, Gap: 5.87e+02, Prim Res: 4.19e+01, Dual Res: 3.06e+00\n",
            "[57000] Primal Obj: 6164.8813, Adjusted Dual Obj: 5341.7793, Gap: 8.23e+02, Prim Res: 2.30e+01, Dual Res: 4.25e+00\n",
            "[58000] Primal Obj: 6064.6094, Adjusted Dual Obj: 5763.0703, Gap: 3.02e+02, Prim Res: 3.20e+01, Dual Res: 3.80e+00\n",
            "[59000] Primal Obj: 6034.6924, Adjusted Dual Obj: 5622.4902, Gap: 4.12e+02, Prim Res: 4.55e+01, Dual Res: 2.82e+00\n",
            "[60000] Primal Obj: 6003.1167, Adjusted Dual Obj: 6576.4458, Gap: 5.73e+02, Prim Res: 4.35e+01, Dual Res: 3.68e+00\n",
            "[61000] Primal Obj: 5965.7485, Adjusted Dual Obj: 6709.7651, Gap: 7.44e+02, Prim Res: 2.70e+01, Dual Res: 6.61e+00\n",
            "[62000] Primal Obj: 5956.3018, Adjusted Dual Obj: 7650.3403, Gap: 1.69e+03, Prim Res: 1.83e+01, Dual Res: 7.13e+00\n",
            "[63000] Primal Obj: 5979.3296, Adjusted Dual Obj: 7189.8076, Gap: 1.21e+03, Prim Res: 3.06e+01, Dual Res: 5.33e+00\n",
            "[64000] Primal Obj: 5990.7388, Adjusted Dual Obj: 6961.9233, Gap: 9.71e+02, Prim Res: 3.83e+01, Dual Res: 3.16e+00\n",
            "[65000] Primal Obj: 5996.1841, Adjusted Dual Obj: 5601.9956, Gap: 3.94e+02, Prim Res: 3.35e+01, Dual Res: 2.69e+00\n",
            "[66000] Primal Obj: 6003.7451, Adjusted Dual Obj: 5050.5767, Gap: 9.53e+02, Prim Res: 2.05e+01, Dual Res: 3.15e+00\n",
            "[67000] Primal Obj: 5985.9883, Adjusted Dual Obj: 4429.1606, Gap: 1.56e+03, Prim Res: 1.98e+01, Dual Res: 3.10e+00\n",
            "[68000] Primal Obj: 5974.9902, Adjusted Dual Obj: 4874.0332, Gap: 1.10e+03, Prim Res: 3.09e+01, Dual Res: 2.43e+00\n",
            "[69000] Primal Obj: 5956.9717, Adjusted Dual Obj: 5861.8179, Gap: 9.52e+01, Prim Res: 3.45e+01, Dual Res: 2.06e+00\n",
            "[70000] Primal Obj: 5859.7700, Adjusted Dual Obj: 6670.6484, Gap: 8.11e+02, Prim Res: 2.84e+01, Dual Res: 3.78e+00\n",
            "[71000] Primal Obj: 5819.0596, Adjusted Dual Obj: 6414.5151, Gap: 5.95e+02, Prim Res: 1.99e+01, Dual Res: 4.75e+00\n",
            "[72000] Primal Obj: 5763.3169, Adjusted Dual Obj: 5808.8540, Gap: 4.55e+01, Prim Res: 2.11e+01, Dual Res: 4.17e+00\n",
            "[73000] Primal Obj: 5712.2983, Adjusted Dual Obj: 5497.2212, Gap: 2.15e+02, Prim Res: 2.70e+01, Dual Res: 2.66e+00\n",
            "[74000] Primal Obj: 5695.6528, Adjusted Dual Obj: 4580.2710, Gap: 1.12e+03, Prim Res: 2.74e+01, Dual Res: 1.97e+00\n",
            "[75000] Primal Obj: 5715.0654, Adjusted Dual Obj: 4922.8872, Gap: 7.92e+02, Prim Res: 2.10e+01, Dual Res: 2.34e+00\n",
            "[76000] Primal Obj: 5682.2139, Adjusted Dual Obj: 4683.7554, Gap: 9.98e+02, Prim Res: 1.31e+01, Dual Res: 2.84e+00\n",
            "[77000] Primal Obj: 5672.8906, Adjusted Dual Obj: 4942.1489, Gap: 7.31e+02, Prim Res: 1.51e+01, Dual Res: 2.82e+00\n",
            "[78000] Primal Obj: 5685.6367, Adjusted Dual Obj: 4625.6514, Gap: 1.06e+03, Prim Res: 2.10e+01, Dual Res: 2.37e+00\n",
            "[79000] Primal Obj: 5700.0435, Adjusted Dual Obj: 5352.9150, Gap: 3.47e+02, Prim Res: 2.09e+01, Dual Res: 2.29e+00\n",
            "[80000] Primal Obj: 5737.5420, Adjusted Dual Obj: 5082.9761, Gap: 6.55e+02, Prim Res: 1.71e+01, Dual Res: 2.88e+00\n",
            "[81000] Primal Obj: 5725.3984, Adjusted Dual Obj: 5862.2236, Gap: 1.37e+02, Prim Res: 1.39e+01, Dual Res: 3.35e+00\n",
            "[82000] Primal Obj: 5721.7661, Adjusted Dual Obj: 5895.7456, Gap: 1.74e+02, Prim Res: 1.60e+01, Dual Res: 2.92e+00\n",
            "[83000] Primal Obj: 5716.3604, Adjusted Dual Obj: 5498.7920, Gap: 2.18e+02, Prim Res: 2.03e+01, Dual Res: 1.86e+00\n",
            "[84000] Primal Obj: 5733.7109, Adjusted Dual Obj: 5136.8247, Gap: 5.97e+02, Prim Res: 2.14e+01, Dual Res: 1.40e+00\n",
            "[85000] Primal Obj: 5756.2656, Adjusted Dual Obj: 4728.6377, Gap: 1.03e+03, Prim Res: 1.79e+01, Dual Res: 1.65e+00\n",
            "[86000] Primal Obj: 5736.0098, Adjusted Dual Obj: 4766.0586, Gap: 9.70e+02, Prim Res: 1.53e+01, Dual Res: 1.84e+00\n",
            "[87000] Primal Obj: 5736.2988, Adjusted Dual Obj: 4794.7476, Gap: 9.42e+02, Prim Res: 1.60e+01, Dual Res: 1.77e+00\n",
            "[88000] Primal Obj: 5714.9409, Adjusted Dual Obj: 5527.7363, Gap: 1.87e+02, Prim Res: 1.78e+01, Dual Res: 1.72e+00\n",
            "[89000] Primal Obj: 5707.8652, Adjusted Dual Obj: 5288.9316, Gap: 4.19e+02, Prim Res: 1.76e+01, Dual Res: 1.63e+00\n",
            "[90000] Primal Obj: 5698.7549, Adjusted Dual Obj: 5762.2617, Gap: 6.35e+01, Prim Res: 1.47e+01, Dual Res: 2.04e+00\n",
            "[91000] Primal Obj: 5685.9731, Adjusted Dual Obj: 5531.0806, Gap: 1.55e+02, Prim Res: 9.94e+00, Dual Res: 2.57e+00\n",
            "[92000] Primal Obj: 5646.8750, Adjusted Dual Obj: 5758.3975, Gap: 1.12e+02, Prim Res: 1.04e+01, Dual Res: 2.41e+00\n",
            "[93000] Primal Obj: 5659.3379, Adjusted Dual Obj: 5472.3291, Gap: 1.87e+02, Prim Res: 1.32e+01, Dual Res: 2.05e+00\n",
            "[94000] Primal Obj: 5642.8306, Adjusted Dual Obj: 5842.8438, Gap: 2.00e+02, Prim Res: 1.39e+01, Dual Res: 1.84e+00\n",
            "[95000] Primal Obj: 5662.6548, Adjusted Dual Obj: 5495.2178, Gap: 1.67e+02, Prim Res: 1.23e+01, Dual Res: 1.82e+00\n",
            "[96000] Primal Obj: 5685.5562, Adjusted Dual Obj: 5450.2031, Gap: 2.35e+02, Prim Res: 1.05e+01, Dual Res: 1.74e+00\n",
            "[97000] Primal Obj: 5694.9292, Adjusted Dual Obj: 5259.9312, Gap: 4.35e+02, Prim Res: 1.12e+01, Dual Res: 1.68e+00\n",
            "[98000] Primal Obj: 5704.1030, Adjusted Dual Obj: 5323.0552, Gap: 3.81e+02, Prim Res: 1.42e+01, Dual Res: 1.32e+00\n",
            "[99000] Primal Obj: 5725.6245, Adjusted Dual Obj: 5717.2217, Gap: 8.40e+00, Prim Res: 1.55e+01, Dual Res: 1.21e+00\n",
            "Converged at iteration 99000\n",
            "Elapsed time: 38.344919 seconds\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "# --- Device Selection ---\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"PyTorch is using ROCm/CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"ROCm/CUDA not available. PyTorch is using CPU.\")\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "    mps_file_path = '25fv47.mps'\n",
        "\n",
        "\n",
        "# --- Data Loading ---\n",
        "    try:\n",
        "        c, G, h, A, b, l, u = mps_to_standard_form_torch(mps_file_path, device=device)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load MPS file: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    is_neg_inf = torch.isinf(l) & (l < 0)\n",
        "    is_pos_inf = torch.isinf(u) & (u > 0)\n",
        "\n",
        "    l_dual = l.clone()\n",
        "    u_dual = u.clone()\n",
        "\n",
        "    l_dual[is_neg_inf] = 0\n",
        "    u_dual[is_pos_inf] = 0\n",
        "    \n",
        "    with Timer():\n",
        "    # --- Run PDHG Solver on the GPU or CPU ---\n",
        "        _, obj, k = pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf, l_dual, u_dual, device=device, max_iter=100000, tol=1e-2, verbose=True, term_period=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1db85ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # --- Device Selection ---\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f\"PyTorch is using ROCm/CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(\"ROCm/CUDA not available. PyTorch is using CPU.\")\n",
        "\n",
        "    num_threads = torch.get_num_threads()\n",
        "    print(f\"PyTorch is running on {num_threads} threads.\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    mps_folder_path = 'feasible'\n",
        "    max_iter = 100000\n",
        "    tol = 1e-2\n",
        "    results = []\n",
        "\n",
        "    # --- Get all MPS files from the folder ---\n",
        "    mps_files = sorted([f for f in os.listdir(mps_folder_path) if f.endswith('.mps')])\n",
        "\n",
        "    for mps_file in mps_files:\n",
        "        mps_file_path = os.path.join(mps_folder_path, mps_file)\n",
        "        print(f\"\\nProcessing {mps_file_path}...\")\n",
        "\n",
        "        try:\n",
        "            # --- Load problem ---\n",
        "            c, G, h, A, b, l, u = mps_to_standard_form_torch(mps_file_path, device=device)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load MPS file: {mps_file_path}. Error: {e}\")\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': 'N/A',\n",
        "                'Iterations (k)': 'N/A',\n",
        "                'Time (s)': 'N/A',\n",
        "                'Status': f'Failed to load: {e}'\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        is_neg_inf = torch.isinf(l) & (l < 0)\n",
        "        is_pos_inf = torch.isinf(u) & (u > 0)\n",
        "\n",
        "        l_dual = l.clone()\n",
        "        u_dual = u.clone()\n",
        "        l_dual[is_neg_inf] = 0\n",
        "        u_dual[is_pos_inf] = 0\n",
        "\n",
        "        # --- Solve ---\n",
        "        try:\n",
        "            with Timer(\"Solve time\") as t:\n",
        "                x, obj, k = pdhg_torch(c, G, h, A, b, l, u, is_neg_inf, is_pos_inf,\n",
        "                                       l_dual, u_dual, device=device,\n",
        "                                       max_iter=max_iter, tol=tol, verbose=False)\n",
        "            time_elapsed = t.elapsed\n",
        "\n",
        "            status = \"Solved\"\n",
        "            if k == max_iter - 1:\n",
        "                status = \"Unsolved (max iterations reached)\"\n",
        "\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': obj,\n",
        "                'Iterations (k)': k,\n",
        "                'Time (s)': time_elapsed,\n",
        "                'Status': status\n",
        "            })\n",
        "\n",
        "            print(f\"Finished: {mps_file}, Time: {time_elapsed:.2f}s, Iter: {k}, Obj: {obj:.4f}, Status: {status}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Solver failed for {mps_file}. Error: {e}\")\n",
        "            results.append({\n",
        "                'File': mps_file,\n",
        "                'Objective': 'N/A',\n",
        "                'Iterations (k)': 'N/A',\n",
        "                'Time (s)': 'N/A',\n",
        "                'Status': f'Solver failed: {e}'\n",
        "            })\n",
        "\n",
        "    # --- Save results to Excel ---\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_excel('pdhg_results.xlsx', index=False)\n",
        "    print(\"\\nAll done. Results saved to pdhg_results.xlsx.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cosc410",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
