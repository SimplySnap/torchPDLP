{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6970982-e9c8-4cd0-a0ca-543ff00ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pulp in ./.local/lib/python3.9/site-packages (3.2.1)\n",
      "Requirement already satisfied: cplex in ./.local/lib/python3.9/site-packages (22.1.2.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /share/sw/ai/pytorch/2.7.1 (from scipy) (2.0.2)\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home1/cphillips/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home1/cphillips/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pulp cplex scipy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41aefc60-d1e7-4de1-bc98-3a60cdcbd11c",
   "metadata": {},
   "source": [
    "The general form of LP problems we will consider is:\n",
    "\n",
    "        min_x  cᵀx\n",
    "   subject to  Gx ≥ h\n",
    "               Ax = b\n",
    "               l ≤ x ≤ u\n",
    "\n",
    "The benchmark datasets use the .mps format for LP problems so there is a function to extract the parameters from this file type into the form above. But since I haven't figured out how to access these datasets yet there is also a function to generate large feasible LP example problems in the .mps format. Finally, there is a preliminary function that implements the PDHG algorithm but not yet any of the enhancments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6990fd1-e684-4a7e-b118-3b454955f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import random as sparse_random\n",
    "import pulp\n",
    "\n",
    "# This function generates large feasible LP problems to test and saves them in the .mps format\n",
    "def generate_feasible_lp(num_vars=100, num_ineq=200, num_eq=50, density=0.05, mps_filename=\"generated_lp.mps\"):\n",
    "    \n",
    "    # The number of variables in each constraint with nonzero coefficients will be roughly density * num_vars\n",
    "    \n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    # Step 1: Feasible solution\n",
    "    x_feas = rng.uniform(low=-10, high=10, size=(num_vars, 1))\n",
    "\n",
    "    # Step 2: Sparse matrices (convert to dense)\n",
    "    G_sparse = sparse_random(num_ineq, num_vars, density=density, format='csr', random_state=None)\n",
    "    A_sparse = sparse_random(num_eq, num_vars, density=density, format='csr', random_state=None)\n",
    "\n",
    "    G = G_sparse.toarray()\n",
    "    A = A_sparse.toarray()\n",
    "\n",
    "    # Step 3: RHS vectors\n",
    "    h = G @ x_feas + rng.uniform(0.1, 5.0, size=(num_ineq, 1))\n",
    "    b = A @ x_feas\n",
    "\n",
    "    # Step 4: Bounds\n",
    "    l = x_feas - rng.uniform(1, 5, size=(num_vars, 1))\n",
    "    u = x_feas + rng.uniform(1, 5, size=(num_vars, 1))\n",
    "    l = np.maximum(l, -1e4)\n",
    "    u = np.minimum(u, 1e4)\n",
    "\n",
    "    # Step 5: Objective\n",
    "    c = rng.normal(size=(num_vars, 1))\n",
    "\n",
    "    # Step 6: Write to MPS using pulp\n",
    "    prob = pulp.LpProblem(\"Feasible_LP\", pulp.LpMinimize)\n",
    "    x_vars = [\n",
    "        pulp.LpVariable(f\"x{i}\", lowBound=float(l[i]), upBound=float(u[i]))\n",
    "        for i in range(num_vars)\n",
    "    ]\n",
    "    prob += pulp.lpDot(c.flatten(), x_vars)\n",
    "\n",
    "    # Inequality constraints: Gx <= h\n",
    "    for i in range(num_ineq):\n",
    "        prob += pulp.lpDot(G[i], x_vars) <= float(h[i]), f\"ineq_{i}\"\n",
    "\n",
    "    # Equality constraints: Ax = b\n",
    "    for i in range(num_eq):\n",
    "        prob += pulp.lpDot(A[i], x_vars) == float(b[i]), f\"eq_{i}\"\n",
    "\n",
    "    prob.writeMPS(mps_filename)\n",
    "    print(f\"✅ LP written to: {mps_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d2c3424-4a61-4caa-990e-f3f0a146dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError\n",
    "\n",
    "# This function extracts the parameters of the LP from the .mps format to the general form\n",
    "def mps_to_standard_form(mps_file):\n",
    "    try:\n",
    "        cpx = cplex.Cplex(mps_file)\n",
    "        cpx.set_results_stream(None)  # mute output\n",
    "\n",
    "        # Number of variables and constraints\n",
    "        num_vars = cpx.variables.get_num()\n",
    "        num_constraints = cpx.linear_constraints.get_num()\n",
    "\n",
    "        # Objective vector (c)\n",
    "        c = np.array(cpx.objective.get_linear())\n",
    "\n",
    "        # Constraint matrix\n",
    "        A_full = cpx.linear_constraints.get_rows()\n",
    "        senses = cpx.linear_constraints.get_senses()\n",
    "        rhs = np.array(cpx.linear_constraints.get_rhs())\n",
    "\n",
    "        A = []\n",
    "        G = []\n",
    "        b = []\n",
    "        h = []\n",
    "\n",
    "        for i, (row, sense, rhs_i) in enumerate(zip(A_full, senses, rhs)):\n",
    "            row_vec = np.zeros(num_vars)\n",
    "            for idx, val in zip(row.ind, row.val):\n",
    "                row_vec[idx] = val\n",
    "            if sense == 'E':  # Equality constraint\n",
    "                A.append(row_vec)\n",
    "                b.append(rhs_i)\n",
    "            elif sense == 'G':  # Greater than or equal\n",
    "                G.append(row_vec)\n",
    "                h.append(rhs_i)\n",
    "            elif sense == 'L':  # Less than or equal\n",
    "                # convert to -Gx ≥ -h\n",
    "                G.append(-row_vec)\n",
    "                h.append(-rhs_i)\n",
    "\n",
    "        A = np.array(A) if A else np.zeros((0, num_vars))\n",
    "        b = np.array(b) if b else np.zeros(0)\n",
    "        G = np.array(G) if G else np.zeros((0, num_vars))\n",
    "        h = np.array(h) if h else np.zeros(0)\n",
    "\n",
    "        # Bounds\n",
    "        l = np.array(cpx.variables.get_lower_bounds())\n",
    "        u = np.array(cpx.variables.get_upper_bounds())\n",
    "\n",
    "        c = c.reshape(-1, 1)\n",
    "        h = h.reshape(-1, 1)\n",
    "        b = b.reshape(-1, 1)\n",
    "        l = l.reshape(-1, 1)\n",
    "        u = u.reshape(-1, 1)\n",
    "        \n",
    "        return c, G, h, A, b, l, u\n",
    "\n",
    "    except CplexError as e:\n",
    "        print(\"CPLEX Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75168b1a-a47b-47d9-bda7-719483cc90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This function iterates the primal-dual hybrid gradient algorithm, without any enhancements, for a specified number of iterations\n",
    "def pdhg(c, G, h, A, b, l, u, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Solves:\n",
    "        min cᵀx s.t. Gx ≥ h, Ax = b, l ≤ x ≤ u\n",
    "    using PDHG algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Parameters\n",
    "    eta = 0.9/np.linalg.norm(np.vstack([G,A]), 2)\n",
    "    omega = 1\n",
    "\n",
    "    tau = eta/omega\n",
    "    sigma = eta*omega\n",
    "    \n",
    "    m_eq = A.shape[0]\n",
    "    m_ineq = G.shape[0]\n",
    "    n = c.shape[0]\n",
    "\n",
    "    # Initialize Primal and Dual Variables\n",
    "    x = np.minimum(np.maximum(np.zeros((n, 1)), l), u)\n",
    "    y = np.zeros((m_eq, 1))       # for Ax = b\n",
    "    z = np.zeros((m_ineq, 1))     # for Gx ≥ h → dual z ≥ 0\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        \n",
    "        # Primal update\n",
    "        x_old = x.copy()\n",
    "        # Project x onto box constraints l ≤ x ≤ u\n",
    "        x = np.minimum(np.maximum(x - tau * (c - A.T @ y - G.T @ z), l), u)\n",
    "\n",
    "        # Dual update\n",
    "        y += sigma * (b - A @ (2*x - x_old))\n",
    "        z += sigma * (h - G @ (2*x - x_old))\n",
    "        z = np.maximum(z, 0)  # project onto constraint z ≥ 0\n",
    "\n",
    "        \n",
    "    # Returns minimal objective value, and minimizer estimate in list format\n",
    "    return (c.T @ x)[0][0], x.T[0].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1924a62-a140-4799-aff4-412e3835b595",
   "metadata": {},
   "source": [
    "Testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbd5f035-9038-4cbe-a797-c4fd45ffac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_442860/2499066835.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pulp.LpVariable(f\"x{i}\", lowBound=float(l[i]), upBound=float(u[i]))\n",
      "/tmp/ipykernel_442860/2499066835.py:45: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prob += pulp.lpDot(G[i], x_vars) <= float(h[i]), f\"ineq_{i}\"\n",
      "/tmp/ipykernel_442860/2499066835.py:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prob += pulp.lpDot(A[i], x_vars) == float(b[i]), f\"eq_{i}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LP written to: large_example.mps\n"
     ]
    }
   ],
   "source": [
    "# Create a feasible LP problem and save to a \n",
    "generate_feasible_lp(num_vars=1000, num_ineq=500, num_eq=500, density=0.05, mps_filename=\"large_example.mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebf3cab3-6d82-4eb4-a405-01fa4d7bdacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected objective sense:  MINIMIZE\n",
      "Selected objective  name:  OBJ\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BND\n",
      "Version identifier: 22.1.2.0 | 2024-12-10 | f4cec290b\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "Linear dependency checker was stopped due to maximum work limit.\n",
      "No LP presolve or aggregator reductions.\n",
      "Presolve time = 0.03 sec. (82.34 ticks)\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =         -2373.017074\n",
      "Iteration:    62   Dual objective     =         -1998.000634\n",
      "Iteration:   124   Dual objective     =         -1939.518523\n",
      "Iteration:   186   Dual objective     =         -1890.210059\n",
      "Iteration:   248   Dual objective     =         -1828.087799\n",
      "Iteration:   310   Dual objective     =         -1761.047066\n",
      "Iteration:   372   Dual objective     =         -1714.663805\n",
      "Iteration:   438   Dual objective     =         -1659.087035\n",
      "Iteration:   504   Dual objective     =         -1601.461618\n",
      "Iteration:   573   Dual objective     =         -1551.616950\n",
      "Iteration:   643   Dual objective     =         -1504.182193\n",
      "Iteration:   724   Dual objective     =         -1436.213558\n",
      "Iteration:   816   Dual objective     =         -1372.953995\n",
      "Iteration:   915   Dual objective     =         -1323.530476\n",
      "Iteration:  1003   Dual objective     =         -1273.208815\n",
      "Iteration:  1095   Dual objective     =         -1211.953647\n",
      "Iteration:  1202   Dual objective     =         -1166.534440\n",
      "Iteration:  1305   Dual objective     =         -1119.128827\n",
      "Iteration:  1419   Dual objective     =         -1086.141554\n",
      "Iteration:  1547   Dual objective     =         -1059.502497\n",
      "Iteration:  1663   Dual objective     =         -1038.976474\n",
      "Iteration:  1796   Dual objective     =         -1023.309050\n",
      "Iteration:  1930   Dual objective     =         -1009.069388\n",
      "Iteration:  2071   Dual objective     =          -996.533774\n",
      "Iteration:  2211   Dual objective     =          -985.999537\n",
      "Iteration:  2359   Dual objective     =          -978.379315\n",
      "Removing shift (1).\n",
      "Objective value: -974.5560349275929\n"
     ]
    }
   ],
   "source": [
    "import cplex\n",
    "\n",
    "# Solve the LP using either primal simplex, dual simplex, or barrier (interior point).\n",
    "# Only works for LP with no more than 1000 constraints and no more than 1000 variables\n",
    "cpx = cplex.Cplex(\"large_example.mps\")\n",
    "cpx.solve()\n",
    "\n",
    "# Save the minimizer and minimal objective values for comparison\n",
    "cpx_obj_val = cpx.solution.get_objective_value()\n",
    "cpx_min = cpx.solution.get_values()\n",
    "print(\"Objective value:\", cpx_obj_val)\n",
    "#print(\"Minimizer: xᵀ =\", cpx_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "966b5f25-ac4d-4d65-98fd-840774dfd404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected objective sense:  MINIMIZE\n",
      "Selected objective  name:  OBJ\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BND\n",
      "Objective Value: -974.553989520326\n",
      "Distance: 0.016839848880211453\n"
     ]
    }
   ],
   "source": [
    "# Extract LP parameters from generated example\n",
    "c, G, h, A, b, l, u = mps_to_standard_form(\"large_example.mps\")\n",
    "pdhg_obj_val, pdhg_min = pdhg(c, G, h, A, b, l, u, max_iter=100000)\n",
    "print(\"Objective Value:\", pdhg_obj_val)\n",
    "#print(\"Minimizer: xᵀ =\",pdhg_min)\n",
    "\n",
    "# The distance between the two minimizer solutions\n",
    "# Should be small but won't be incredibly small since the vectors are high dimensional\n",
    "distance = np.linalg.norm(np.array(pdhg_min) - np.array(cpx_min))\n",
    "print(\"Distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8d0af2-1202-4f14-8617-9f04b288441d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "/opt/rocm-6.3.1/lib/libamd_smi.so: undefined symbol: amdsmi_get_gpu_enumeration_info",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/share/sw/ai/pytorch/2.7.1/torch/__init__.py:2064\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find torch_shm_manager at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path)\n\u001b[1;32m   2061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2064\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[0;32m/share/sw/ai/pytorch/2.7.1/torch/cuda/__init__.py:108\u001b[0m\n\u001b[1;32m    105\u001b[0m                 ctypes\u001b[38;5;241m.\u001b[39mCDLL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_CDLL  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _amdsmi_cdll_hook():\n\u001b[0;32m--> 108\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mamdsmi\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     _HAS_PYNVML \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/rocm-6.4.1/share/amd_smi/amdsmi/__init__.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Library Initialization\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamdsmi_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m amdsmi_init\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamdsmi_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m amdsmi_shut_down\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Device Discovery\u001b[39;00m\n",
      "File \u001b[0;32m/opt/rocm-6.4.1/share/amd_smi/amdsmi/amdsmi_interface.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asctime, localtime, time\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Tuple, Union\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m amdsmi_wrapper\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamdsmi_exception\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m### Non Library Specific Constants ###\u001b[39;00m\n",
      "File \u001b[0;32m/opt/rocm-6.4.1/share/amd_smi/amdsmi/amdsmi_wrapper.py:2305\u001b[0m\n\u001b[1;32m   2303\u001b[0m amdsmi_get_gpu_device_uuid\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m amdsmi_status_t\n\u001b[1;32m   2304\u001b[0m amdsmi_get_gpu_device_uuid\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [amdsmi_processor_handle, ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_uint32), ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char)]\n\u001b[0;32m-> 2305\u001b[0m amdsmi_get_gpu_enumeration_info \u001b[38;5;241m=\u001b[39m \u001b[43m_libraries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibamd_smi.so\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamdsmi_get_gpu_enumeration_info\u001b[49m\n\u001b[1;32m   2306\u001b[0m amdsmi_get_gpu_enumeration_info\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m amdsmi_status_t\n\u001b[1;32m   2307\u001b[0m amdsmi_get_gpu_enumeration_info\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [amdsmi_processor_handle, ctypes\u001b[38;5;241m.\u001b[39mPOINTER(struct_amdsmi_enumeration_info_t)]\n",
      "File \u001b[0;32m/usr/lib64/python3.9/ctypes/__init__.py:387\u001b[0m, in \u001b[0;36mCDLL.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 387\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, func)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m/usr/lib64/python3.9/ctypes/__init__.py:392\u001b[0m, in \u001b[0;36mCDLL.__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_ordinal):\n\u001b[0;32m--> 392\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_FuncPtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_ordinal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_ordinal, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    394\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name_or_ordinal\n",
      "\u001b[0;31mAttributeError\u001b[0m: /opt/rocm-6.3.1/lib/libamd_smi.so: undefined symbol: amdsmi_get_gpu_enumeration_info"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "N = 10000\n",
    "k = 20\n",
    "x = torch.randn(N, N, device=device)\n",
    "y = torch.randn(N, N, device=device)\n",
    "\n",
    "# Warm up\n",
    "for _ in range(5):\n",
    "    _ = torch.matmul(x, y)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(k):\n",
    "    _ = torch.matmul(x, y)\n",
    "torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "end = time.time()\n",
    "\n",
    "elapsed = end - start\n",
    "total_flops = 2 * (N ** 3) * k\n",
    "tflops = total_flops / (elapsed * 1e12)\n",
    "\n",
    "print(f\"Time for {k} matrix multiplications of {N}x{N}: {elapsed:.3f} seconds\")\n",
    "print(f\"Average time per multiplication: {elapsed/k:.3f} seconds\")\n",
    "print(f\"Approximate performance: {tflops:.3f} TFLOPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e27d4-bd17-4a30-907e-494f60ea8ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
