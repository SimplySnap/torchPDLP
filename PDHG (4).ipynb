{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6970982-e9c8-4cd0-a0ca-543ff00ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pulp in ./.local/lib/python3.9/site-packages (3.2.1)\n",
      "Requirement already satisfied: cplex in ./.local/lib/python3.9/site-packages (22.1.2.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /share/sw/ai/pytorch/2.7.1 (from scipy) (2.0.2)\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home1/cphillips/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home1/cphillips/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pulp cplex scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85453f-5f8b-47cc-a60f-b499d6fb75ec",
   "metadata": {},
   "source": [
    "The general form of LP problems we will consider is:\n",
    "\n",
    "        min_x  cᵀx\n",
    "   subject to  Gx ≥ h\n",
    "               Ax = b\n",
    "               l ≤ x ≤ u\n",
    "\n",
    "The benchmark datasets use the .mps format for LP problems so there is a function to extract the parameters from this file type into the form above. But since I haven't figured out how to access these datasets yet there is also a function to generate large feasible LP example problems in the .mps format. Finally, there is a preliminary function that implements the PDHG algorithm but not yet any of the enhancments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6990fd1-e684-4a7e-b118-3b454955f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import random as sparse_random\n",
    "import pulp\n",
    "\n",
    "# This function generates large feasible LP problems to test and saves them in the .mps format\n",
    "def generate_feasible_lp(num_vars=100, num_ineq=200, num_eq=50, density=0.05, mps_filename=\"generated_lp.mps\"):\n",
    "    \n",
    "    # The number of variables in each constraint with nonzero coefficients will be roughly density * num_vars\n",
    "    \n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    # Step 1: Feasible solution\n",
    "    x_feas = rng.uniform(low=-10, high=10, size=(num_vars, 1))\n",
    "    \n",
    "    # Step 2: Sparse matrices (convert to dense)\n",
    "    G_sparse = sparse_random(num_ineq, num_vars, density=density, format='csr', random_state=None)\n",
    "    A_sparse = sparse_random(num_eq, num_vars, density=density, format='csr', random_state=None)\n",
    "\n",
    "    G = G_sparse.toarray()\n",
    "    A = A_sparse.toarray()\n",
    "\n",
    "    # Step 3: RHS vectors\n",
    "    h = G @ x_feas #+ rng.uniform(0.1, 5.0, size=(num_ineq, 1))\n",
    "    b = A @ x_feas\n",
    "\n",
    "    # Step 4: Bounds\n",
    "    l = x_feas - rng.uniform(1, 5, size=(num_vars, 1))\n",
    "    u = x_feas + rng.uniform(1, 5, size=(num_vars, 1))\n",
    "    l = np.maximum(l, -1e4)\n",
    "    u = np.minimum(u, 1e4)\n",
    "\n",
    "    # Step 5: Objective\n",
    "    c = rng.normal(size=(num_vars, 1))\n",
    "\n",
    "    # Step 6: Write to MPS using pulp\n",
    "    prob = pulp.LpProblem(\"Feasible_LP\", pulp.LpMinimize)\n",
    "    x_vars = [\n",
    "        pulp.LpVariable(f\"x{i}\", lowBound=float(l[i]), upBound=float(u[i]))\n",
    "        for i in range(num_vars)\n",
    "    ]\n",
    "    prob += pulp.lpDot(c.flatten(), x_vars)\n",
    "\n",
    "    # Inequality constraints: Gx <= h\n",
    "    for i in range(num_ineq):\n",
    "        prob += pulp.lpDot(G[i], x_vars) <= float(h[i]), f\"ineq_{i}\"\n",
    "\n",
    "    # Equality constraints: Ax = b\n",
    "    for i in range(num_eq):\n",
    "        prob += pulp.lpDot(A[i], x_vars) == float(b[i]), f\"eq_{i}\"\n",
    "\n",
    "    prob.writeMPS(mps_filename)\n",
    "    print(f\"LP written to: {mps_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2c3424-4a61-4caa-990e-f3f0a146dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError\n",
    "\n",
    "# This function extracts the parameters of the LP from the .mps format to the general form\n",
    "def mps_to_standard_form(mps_file):\n",
    "    try:\n",
    "        cpx = cplex.Cplex(mps_file)\n",
    "        cpx.set_results_stream(None)  # mute output\n",
    "\n",
    "        # Number of variables and constraints\n",
    "        num_vars = cpx.variables.get_num()\n",
    "        num_constraints = cpx.linear_constraints.get_num()\n",
    "\n",
    "        # Objective vector (c)\n",
    "        c = np.array(cpx.objective.get_linear())\n",
    "\n",
    "        # Constraint matrix\n",
    "        A_full = cpx.linear_constraints.get_rows()\n",
    "        senses = cpx.linear_constraints.get_senses()\n",
    "        rhs = np.array(cpx.linear_constraints.get_rhs())\n",
    "\n",
    "        A = []\n",
    "        G = []\n",
    "        b = []\n",
    "        h = []\n",
    "\n",
    "        for i, (row, sense, rhs_i) in enumerate(zip(A_full, senses, rhs)):\n",
    "            row_vec = np.zeros(num_vars)\n",
    "            for idx, val in zip(row.ind, row.val):\n",
    "                row_vec[idx] = val\n",
    "            if sense == 'E':  # Equality constraint\n",
    "                A.append(row_vec)\n",
    "                b.append(rhs_i)\n",
    "            elif sense == 'G':  # Greater than or equal\n",
    "                G.append(row_vec)\n",
    "                h.append(rhs_i)\n",
    "            elif sense == 'L':  # Less than or equal\n",
    "                # convert to -Gx ≥ -h\n",
    "                G.append(-row_vec)\n",
    "                h.append(-rhs_i)\n",
    "\n",
    "        A = np.array(A) if A else np.zeros((0, num_vars))\n",
    "        b = np.array(b) if b else np.zeros(0)\n",
    "        G = np.array(G) if G else np.zeros((0, num_vars))\n",
    "        h = np.array(h) if h else np.zeros(0)\n",
    "\n",
    "        # Bounds\n",
    "        l = np.array(cpx.variables.get_lower_bounds())\n",
    "        u = np.array(cpx.variables.get_upper_bounds())\n",
    "\n",
    "        c = c.reshape(-1, 1)\n",
    "        h = h.reshape(-1, 1)\n",
    "        b = b.reshape(-1, 1)\n",
    "        l = l.reshape(-1, 1)\n",
    "        u = u.reshape(-1, 1)\n",
    "        \n",
    "        return c, G, h, A, b, l, u\n",
    "\n",
    "    except CplexError as e:\n",
    "        print(\"CPLEX Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac77ad94-b5b1-4e75-a60b-65732bf2f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def proj_Lam(lam):\n",
    "    return lam\n",
    "\n",
    "def pdhg(c, G, h, A, b, l, u, max_iter=1000, tol=1e-4, term_period=1000):\n",
    "    \"\"\"\n",
    "    Solves:\n",
    "        min cᵀx s.t. Gx ≥ h, Ax = b, l ≤ x ≤ u\n",
    "    using PDHG algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Parameters\n",
    "    K = np.vstack([G, A])\n",
    "    q = np.vstack([h, b])\n",
    "    \n",
    "    eta = 0.9/np.linalg.norm(K, 2)\n",
    "    omega = 10\n",
    "\n",
    "    tau = eta/omega\n",
    "    sigma = eta*omega\n",
    "    \n",
    "    m_1 = G.shape[0]\n",
    "    m_2 = A.shape[0]\n",
    "    n = c.shape[0]  \n",
    "\n",
    "    # Termination Parameters\n",
    "    tol_dual = tol * (1 + np.linalg.norm(c))\n",
    "    tol_prim = tol * (1 + np.linalg.norm(q))\n",
    "    \n",
    "    # Initialize Primal and Dual Variables\n",
    "    x = np.minimum(np.maximum(np.zeros((n, 1)), l), u)\n",
    "    y = np.zeros((m_1 + m_2, 1))\n",
    "    \n",
    "    for i in range(1, max_iter + 1):\n",
    "        # Primal update\n",
    "        x_old = x.copy()\n",
    "        # Project x onto box constraints l ≤ x ≤ u\n",
    "        grad = c - K.T @ y\n",
    "        x = np.minimum(np.maximum(x - tau * grad, l), u)\n",
    "\n",
    "        # Dual update\n",
    "        y += sigma * (q - K @ (2*x - x_old))\n",
    "        y[:m_1] = np.maximum(y[:m_1], 0)  # project onto constraint y:m_1 ≥ 0\n",
    "        \n",
    "        # Check Termination Criteria Periodically\n",
    "        if i%term_period == 0:\n",
    "            \n",
    "            dual_op = (q.T @ y)[0][0]\n",
    "            prim_op = (c.T @ x)[0][0]\n",
    "\n",
    "            lam_p_op = (l.T @ np.maximum(grad, 0))[0][0]\n",
    "            lam_n_op = (u.T @ np.minimum(grad, 0))[0][0]\n",
    "\n",
    "            #print(dual_op + lam_p_op + lam_n_op, prim_op)\n",
    "            #print(np.linalg.norm(np.vstack([A @ x - b, np.maximum(h - G @ x, 0)])))\n",
    "            #print(np.linalg.norm(np.vstack([A @ x - b, np.maximum(h - G @ x, 0)])), np.linalg.norm(grad - proj_Lam(grad)), np.abs(dual_op + lam_p_op - lam_n_op - prim_op))\n",
    "            #print(tol_dual, tol_prim, tol * (1 + np.abs(dual_op + lam_p_op - lam_n_op) + np.abs(prim_op)))\n",
    "            if (\n",
    "                np.linalg.norm(np.vstack([A @ x - b, np.maximum(h - G @ x, 0)])) <= tol_prim\n",
    "                and np.linalg.norm(grad - proj_Lam(grad)) <= tol_dual\n",
    "                and np.abs(dual_op + lam_p_op + lam_n_op - prim_op) <= tol * (1 + np.abs(dual_op + lam_p_op - lam_n_op) + np.abs(prim_op))\n",
    "            ):\n",
    "                break\n",
    "        \n",
    "    # Returns minimal objective value, minimizer estimate in list format, and the number of iterations run\n",
    "    return (c.T @ x)[0][0], x.T[0].tolist(), i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8b000-1f6c-417c-9da3-1f6d921cccbc",
   "metadata": {},
   "source": [
    "Testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4278777-d23b-4002-8059-03db2d2c20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "# Makes a timer to measure code omtimality\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = perf_counter()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.end = perf_counter()\n",
    "        self.elapsed = self.end - self.start\n",
    "        print(f\"Elapsed time: {self.elapsed:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd5f035-9038-4cbe-a797-c4fd45ffac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147092/277239451.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pulp.LpVariable(f\"x{i}\", lowBound=float(l[i]), upBound=float(u[i]))\n",
      "/tmp/ipykernel_147092/277239451.py:45: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prob += pulp.lpDot(G[i], x_vars) <= float(h[i]), f\"ineq_{i}\"\n",
      "/tmp/ipykernel_147092/277239451.py:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prob += pulp.lpDot(A[i], x_vars) == float(b[i]), f\"eq_{i}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP written to: large_example.mps\n"
     ]
    }
   ],
   "source": [
    "# Create a feasible LP problem and save to a \n",
    "generate_feasible_lp(num_vars=1000, num_ineq=500, num_eq=500, density=0.05, mps_filename=\"large_example.mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf3cab3-6d82-4eb4-a405-01fa4d7bdacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected objective sense:  MINIMIZE\n",
      "Selected objective  name:  OBJ\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BND\n",
      "\n",
      "Selected objective sense:  MINIMIZE\n",
      "Selected objective  name:  OBJ\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BND\n",
      "Version identifier: 22.1.2.0 | 2024-12-10 | f4cec290b\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 1 time.\n",
      "Linear dependency checker was stopped due to maximum work limit.\n",
      "No LP presolve or aggregator reductions.\n",
      "Presolve time = 0.03 sec. (85.68 ticks)\n",
      "\n",
      "Iteration log . . .\n",
      "Iteration:     1   Dual objective     =         -2217.195330\n",
      "Iteration:    62   Dual objective     =         -1872.006221\n",
      "Iteration:   124   Dual objective     =         -1780.895113\n",
      "Iteration:   186   Dual objective     =         -1738.398788\n",
      "Iteration:   248   Dual objective     =         -1661.488818\n",
      "Iteration:   310   Dual objective     =         -1594.576219\n",
      "Iteration:   372   Dual objective     =         -1549.913785\n",
      "Iteration:   434   Dual objective     =         -1503.073374\n",
      "Iteration:   502   Dual objective     =         -1443.249689\n",
      "Iteration:   569   Dual objective     =         -1394.177837\n",
      "Iteration:   644   Dual objective     =         -1332.399413\n",
      "Iteration:   722   Dual objective     =         -1279.477677\n",
      "Iteration:   804   Dual objective     =         -1224.643495\n",
      "Iteration:   888   Dual objective     =         -1160.789912\n",
      "Iteration:   981   Dual objective     =         -1109.654379\n",
      "Iteration:  1077   Dual objective     =         -1060.758398\n",
      "Iteration:  1181   Dual objective     =         -1004.790739\n",
      "Iteration:  1290   Dual objective     =          -948.343208\n",
      "Iteration:  1395   Dual objective     =          -918.746665\n",
      "Iteration:  1501   Dual objective     =          -887.701270\n",
      "Iteration:  1616   Dual objective     =          -850.965495\n",
      "Iteration:  1736   Dual objective     =          -824.560675\n",
      "Iteration:  1868   Dual objective     =          -798.906273\n",
      "Iteration:  1990   Dual objective     =          -782.941061\n",
      "Iteration:  2121   Dual objective     =          -756.329304\n",
      "Iteration:  2253   Dual objective     =          -741.451618\n",
      "Iteration:  2391   Dual objective     =          -728.865058\n",
      "Iteration:  2527   Dual objective     =          -717.252404\n",
      "Iteration:  2667   Dual objective     =          -710.744004\n",
      "Elapsed time: 1.716278 seconds\n",
      "Objective value: -707.0814870269519\n"
     ]
    }
   ],
   "source": [
    "import cplex\n",
    "\n",
    "# Solve the LP using either primal simplex, dual simplex, or barrier (interior point).\n",
    "# Only works for LP with no more than 1000 constraints and no more than 1000 variables\n",
    "cpx = cplex.Cplex(\"large_example.mps\")\n",
    "c, G, h, A, b, l, u = mps_to_standard_form(\"large_example.mps\")\n",
    "\n",
    "# Times how long it takes to solve\n",
    "with Timer():\n",
    "    cpx.solve()\n",
    "\n",
    "# Save the minimizer and minimal objective values for comparison\n",
    "cpx_obj_val = cpx.solution.get_objective_value()\n",
    "cpx_min = cpx.solution.get_values()\n",
    "print(\"Objective value:\", cpx_obj_val)\n",
    "#print(\"Minimizer: xᵀ =\", cpx_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b5f25-ac4d-4d65-98fd-840774dfd404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected objective sense:  MINIMIZE\n",
      "Selected objective  name:  OBJ\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BND\n",
      "7.81201013593375e-06\n"
     ]
    }
   ],
   "source": [
    "# Extract LP parameters from generated example\n",
    "with Timer():\n",
    "    c, G, h, A, b, l, u = mps_to_standard_form(\"large_example.mps\")\n",
    "    pdhg_obj_val, pdhg_min, iterations = pdhg(c, G, h, A, b, l, u, max_iter=1000000, tol=1e-8)\n",
    "print(\"Objective Value:\", pdhg_obj_val)\n",
    "print(\"Iterations:\", iterations)\n",
    "#print(\"Minimizer: xᵀ =\",pdhg_min)\n",
    "\n",
    "# The distance between the two minimizer solutions\n",
    "# Should be small but won't be incredibly small since the vectors are high dimensional\n",
    "#distance = np.linalg.norm(np.array(pdhg_min) - np.array(cpx_min))\n",
    "#print(\"Distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90264995-0efd-48e5-9ffe-3b37cd272752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
