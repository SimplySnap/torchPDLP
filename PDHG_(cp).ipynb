{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c6970982-e9c8-4cd0-a0ca-543ff00ecf79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6970982-e9c8-4cd0-a0ca-543ff00ecf79",
        "outputId": "61e47dca-79d1-4b10-b57a-fd2cf9d3fbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pulp\n",
            "  Using cached pulp-3.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting cplex\n",
            "  Using cached cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Using cached pulp-3.2.1-py3-none-any.whl (16.4 MB)\n",
            "Using cached cplex-22.1.2.0-cp311-cp311-manylinux2014_x86_64.whl (44.3 MB)\n",
            "Installing collected packages: pulp, cplex\n",
            "Successfully installed cplex-22.1.2.0 pulp-3.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pulp cplex scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f85453f-5f8b-47cc-a60f-b499d6fb75ec",
      "metadata": {
        "id": "8f85453f-5f8b-47cc-a60f-b499d6fb75ec"
      },
      "source": [
        "The general form of LP problems we will consider is:\n",
        "\n",
        "        min_x  cᵀx\n",
        "   subject to  Gx ≥ h\n",
        "               Ax = b\n",
        "               l ≤ x ≤ u\n",
        "\n",
        "The benchmark datasets use the .mps format for LP problems so there is a function to extract the parameters from this file type into the form above. But since I haven't figured out how to access these datasets yet there is also a function to generate large feasible LP example problems in the .mps format. Finally, there is a preliminary function that implements the PDHG algorithm but not yet any of the enhancments."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "zVnkBnPXD2JX"
      },
      "id": "zVnkBnPXD2JX"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "d6990fd1-e684-4a7e-b118-3b454955f0eb",
      "metadata": {
        "id": "d6990fd1-e684-4a7e-b118-3b454955f0eb"
      },
      "outputs": [],
      "source": [
        "#Comment out numpy for cupy generation\n",
        "#import numpy as np\n",
        "import cupy as cp\n",
        "from scipy.sparse import random as sparse_random\n",
        "import pulp\n",
        "\n",
        "# This function generates large feasible LP problems to test and saves them in the .mps format\n",
        "def generate_feasible_lp(num_vars=100, num_ineq=200, num_eq=50, density=0.05, mps_filename=\"generated_lp.mps\"):\n",
        "    '''This function generates large feasible LP problems to test and saves them in the .mps format'''\n",
        "\n",
        "    # The number of variables in each constraint with nonzero coefficients will be roughly density * num_vars\n",
        "\n",
        "    rng = cp.random.default_rng(0)\n",
        "\n",
        "    # Step 1: (Random) feasible solution\n",
        "    x_feas = rng.uniform(low=-10, high=10, size=(num_vars, 1))\n",
        "\n",
        "    # Step 2: Sparse matrices (convert to dense)\n",
        "    G_sparse = sparse_random(num_ineq, num_vars, density=density, format='csr', random_state=None)\n",
        "    A_sparse = sparse_random(num_eq, num_vars, density=density, format='csr', random_state=None)\n",
        "\n",
        "    G = G_sparse.toarray()\n",
        "    A = A_sparse.toarray()\n",
        "\n",
        "    #Addition - convert to cupy array\n",
        "    G = cp.array(G)\n",
        "    A = cp.array(A)\n",
        "\n",
        "    # Step 3: RHS vectors\n",
        "    h = G @ x_feas + rng.uniform(0.1, 5.0, size=(num_ineq, 1))\n",
        "    b = A @ x_feas\n",
        "\n",
        "    # Step 4: Bounds\n",
        "    l = x_feas - rng.uniform(1, 5, size=(num_vars, 1))\n",
        "    u = x_feas + rng.uniform(1, 5, size=(num_vars, 1))\n",
        "    l = cp.maximum(l, -1e4)\n",
        "    u = cp.minimum(u, 1e4)\n",
        "\n",
        "    # Step 5: Objective\n",
        "    c = rng.normal(size=(num_vars, 1))\n",
        "\n",
        "    # Step 6: Write to MPS using pulp\n",
        "    prob = pulp.LpProblem(\"Feasible_LP\", pulp.LpMinimize)\n",
        "    x_vars = [\n",
        "        pulp.LpVariable(f\"x{i}\", lowBound=float(l[i]), upBound=float(u[i]))\n",
        "        for i in range(num_vars)\n",
        "    ]\n",
        "    prob += pulp.lpDot(c.flatten(), x_vars)\n",
        "\n",
        "    # Inequality constraints: Gx ≥ h\n",
        "    for i in range(num_ineq):\n",
        "        prob += pulp.lpDot(G[i], x_vars) <= float(h[i]), f\"ineq_{i}\"\n",
        "\n",
        "    # Equality constraints: Ax = b\n",
        "    for i in range(num_eq):\n",
        "        prob += pulp.lpDot(A[i], x_vars) == float(b[i]), f\"eq_{i}\"\n",
        "\n",
        "    prob.writeMPS(mps_filename)\n",
        "    print(f\"LP written to: {mps_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "6d2c3424-4a61-4caa-990e-f3f0a146dd00",
      "metadata": {
        "id": "6d2c3424-4a61-4caa-990e-f3f0a146dd00"
      },
      "outputs": [],
      "source": [
        "#import numpy as np\n",
        "import cplex\n",
        "from cplex.exceptions import CplexError\n",
        "\n",
        "# This function extracts the parameters of the LP from the .mps format to the general form\n",
        "def mps_to_standard_form(mps_file):\n",
        "    '''\n",
        "    Extracts the parameters of the LP from the .mps format to the general form\n",
        "    Returns c, G ineq matrix, h ineq vec, A eq matrix, b eq vec, l and u lower and\n",
        "    upper box constraints\n",
        "    '''\n",
        "    try:\n",
        "        cpx = cplex.Cplex(mps_file)\n",
        "        cpx.set_results_stream(None)  # mute output\n",
        "\n",
        "        # Number of variables and constraints\n",
        "        num_vars = cpx.variables.get_num()\n",
        "        num_constraints = cpx.linear_constraints.get_num()\n",
        "\n",
        "        # Objective vector (c)\n",
        "        c = cp.array(cpx.objective.get_linear())\n",
        "\n",
        "        # Constraint matrix\n",
        "        A_full = cpx.linear_constraints.get_rows()\n",
        "        senses = cpx.linear_constraints.get_senses()\n",
        "        rhs = cp.array(cpx.linear_constraints.get_rhs())\n",
        "\n",
        "        A = []\n",
        "        G = []\n",
        "        b = []\n",
        "        h = []\n",
        "\n",
        "        for i, (row, sense, rhs_i) in enumerate(zip(A_full, senses, rhs)):\n",
        "            row_vec = cp.zeros(num_vars)\n",
        "            for idx, val in zip(row.ind, row.val):\n",
        "                row_vec[idx] = val\n",
        "            if sense == 'E':  # Equality constraint\n",
        "                A.append(row_vec)\n",
        "                b.append(rhs_i)\n",
        "            elif sense == 'G':  # Greater than or equal\n",
        "                G.append(row_vec)\n",
        "                h.append(rhs_i)\n",
        "            elif sense == 'L':  # Less than or equal\n",
        "                # convert to -Gx ≥ -h\n",
        "                G.append(-row_vec)\n",
        "                h.append(-rhs_i)\n",
        "\n",
        "        A = cp.array(A) if A else cp.zeros((0, num_vars))\n",
        "        b = cp.array(b) if b else cp.zeros(0)\n",
        "        G = cp.array(G) if G else cp.zeros((0, num_vars))\n",
        "        h = cp.array(h) if h else cp.zeros(0)\n",
        "\n",
        "        # Bounds\n",
        "        l = cp.array(cpx.variables.get_lower_bounds())\n",
        "        u = cp.array(cpx.variables.get_upper_bounds())\n",
        "\n",
        "        c = c.reshape(-1, 1)\n",
        "        h = h.reshape(-1, 1)\n",
        "        b = b.reshape(-1, 1)\n",
        "        l = l.reshape(-1, 1)\n",
        "        u = u.reshape(-1, 1)\n",
        "\n",
        "        return c, G, h, A, b, l, u\n",
        "\n",
        "    except CplexError as e:\n",
        "        print(\"CPLEX Error:\", e)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "ac77ad94-b5b1-4e75-a60b-65732bf2f00d",
      "metadata": {
        "id": "ac77ad94-b5b1-4e75-a60b-65732bf2f00d"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "def proj_Lam(lam):\n",
        "    return lam\n",
        "\n",
        "         # LP parameters, maximum iterations, error tolerance, period checks termination criteria\n",
        "def pdhg(c, G, h, A, b, l, u, max_iter=1000, tol=1e-4, term_period=1000):\n",
        "    \"\"\"\n",
        "    Solves:\n",
        "        min cᵀx s.t. Gx ≥ h, Ax = b, l ≤ x ≤ u\n",
        "    using PDHG algorithm.\n",
        "    Returns minimal objective value, minimizer estimate in list format, and the number of iterations run\n",
        "    \"\"\"\n",
        "\n",
        "    # Define Parameters\n",
        "    K = cp.vstack([G, A])\n",
        "    q = cp.vstack([h, b])\n",
        "\n",
        "    eta = 0.9/cp.linalg.norm(K, 2)\n",
        "    omega = 10\n",
        "\n",
        "    tau = eta/omega\n",
        "    sigma = eta*omega\n",
        "\n",
        "    m_1 = G.shape[0]\n",
        "    m_2 = A.shape[0]\n",
        "    n = c.shape[0]\n",
        "\n",
        "    # Termination Parameters\n",
        "    tol_dual = tol * (1 + cp.linalg.norm(c))\n",
        "    tol_prim = tol * (1 + cp.linalg.norm(q))\n",
        "\n",
        "    # Initialize Primal and Dual Variables\n",
        "    x = cp.minimum(cp.maximum(cp.zeros((n, 1)), l), u)\n",
        "    y = cp.zeros((m_1 + m_2, 1))\n",
        "\n",
        "    for i in range(1, max_iter + 1):\n",
        "        # Primal update\n",
        "        x_old = x.copy()\n",
        "        # Project x onto box constraints l ≤ x ≤ u\n",
        "        grad = c - K.T @ y\n",
        "        x = cp.minimum(cp.maximum(x - tau * grad, l), u)\n",
        "\n",
        "        # Dual update\n",
        "        y += sigma * (q - K @ (2*x - x_old))\n",
        "        y[:m_1] = cp.maximum(y[:m_1], 0)  # project onto constraint y:m_1 ≥ 0\n",
        "\n",
        "        # Check Termination Criteria Periodically\n",
        "        if i%term_period == 0:\n",
        "\n",
        "            dual_op = (q.T @ y)[0][0]\n",
        "            prim_op = (c.T @ x)[0][0]\n",
        "\n",
        "            lam_p_op = (l.T @ cp.maximum(grad, 0))[0][0]\n",
        "            lam_n_op = (u.T @ cp.minimum(grad, 0))[0][0]\n",
        "\n",
        "            '''Print [uncomment] for debugging'''\n",
        "            #print(dual_op + lam_p_op + lam_n_op, prim_op)\n",
        "            #print(cp.linalg.norm(cp.vstack([A @ x - b, cp.maximum(h - G @ x, 0)])))\n",
        "            print(cp.linalg.norm(cp.vstack([A @ x - b, cp.maximum(h - G @ x, 0)])), cp.linalg.norm(grad - proj_Lam(grad)), cp.abs(dual_op + lam_p_op - lam_n_op - prim_op))\n",
        "            #print(tol_dual, tol_prim, tol * (1 + cp.abs(dual_op + lam_p_op - lam_n_op) + cp.abs(prim_op)))\n",
        "            if (\n",
        "                cp.linalg.norm(cp.vstack([A @ x - b, cp.maximum(h - G @ x, 0)])) <= tol_prim  # Primal Feasibility\n",
        "                and cp.linalg.norm(grad - proj_Lam(grad)) <= tol_dual  # Dual Feasibility\n",
        "                and cp.abs(dual_op + lam_p_op + lam_n_op - prim_op) <= tol * (1 + cp.abs(dual_op + lam_p_op + lam_n_op) + cp.abs(prim_op))  # Duality Gap\n",
        "            ):\n",
        "                break\n",
        "\n",
        "    # Returns minimal objective value, minimizer estimate in list format, and the number of iterations run\n",
        "    return (c.T @ x)[0][0], x.T[0].tolist(), i"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f36933a",
      "metadata": {
        "id": "6f36933a"
      },
      "source": [
        "# Testing the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "0adfd9e9",
      "metadata": {
        "id": "0adfd9e9"
      },
      "outputs": [],
      "source": [
        "from time import perf_counter\n",
        "\n",
        "# Makes a timer to measure code omtimality\n",
        "class Timer:\n",
        "    def __enter__(self):\n",
        "        self.start = perf_counter()\n",
        "        return self\n",
        "    def __exit__(self, *args):\n",
        "        self.end = perf_counter()\n",
        "        self.elapsed = self.end - self.start\n",
        "        print(f\"Elapsed time: {self.elapsed:.6f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "8cd5807e",
      "metadata": {
        "id": "8cd5807e"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "from scipy.sparse import random as sparse_random\n",
        "import pulp\n",
        "import numpy as np\n",
        "\n",
        "# This function generates large feasible LP problems to test and saves them in the .mps format\n",
        "def generate_feasible_lp(num_vars=100, num_ineq=200, num_eq=50, density=0.05, mps_filename=\"generated_lp.mps\"):\n",
        "    '''This function generates large feasible LP problems to test and saves them in the .mps format'''\n",
        "\n",
        "    # The number of variables in each constraint with nonzero coefficients will be roughly density * num_vars\n",
        "\n",
        "    rng = cp.random.default_rng(0)\n",
        "\n",
        "    # Step 1: (Random) feasible solution\n",
        "    x_feas = rng.uniform(low=-10, high=10, size=(num_vars, 1))\n",
        "\n",
        "    # Step 2: Sparse matrices (convert to dense)\n",
        "    G_sparse = sparse_random(num_ineq, num_vars, density=density, format='csr', random_state=None)\n",
        "    A_sparse = sparse_random(num_eq, num_vars, density=density, format='csr', random_state=None)\n",
        "\n",
        "    G = G_sparse.toarray()\n",
        "    A = A_sparse.toarray()\n",
        "\n",
        "    #cupy array\n",
        "    G = cp.array(G)\n",
        "    A = cp.array(A)\n",
        "\n",
        "    # Step 3: RHS vectors\n",
        "    h = G @ x_feas + rng.uniform(0.1, 5.0, size=(num_ineq, 1))\n",
        "    b = A @ x_feas\n",
        "\n",
        "    # Step 4: Bounds\n",
        "    l = x_feas - rng.uniform(1, 5, size=(num_vars, 1))\n",
        "    u = x_feas + rng.uniform(1, 5, size=(num_vars, 1))\n",
        "    l = cp.maximum(l, -1e4)\n",
        "    u = cp.minimum(u, 1e4)\n",
        "\n",
        "    # Step 5: Objective\n",
        "    c = cp.random.normal(size=(num_vars, 1))\n",
        "\n",
        "    # Step 6: Write to MPS using pulp\n",
        "    prob = pulp.LpProblem(\"Feasible_LP\", pulp.LpMinimize)\n",
        "    x_vars = [\n",
        "        pulp.LpVariable(f\"x{i}\", lowBound=float(l[i].get()), upBound=float(u[i].get()))\n",
        "        for i in range(num_vars)\n",
        "    ]\n",
        "    prob += pulp.lpDot(c.flatten().get(), x_vars)\n",
        "\n",
        "    # Inequality constraints: Gx ≥ h\n",
        "    for i in range(num_ineq):\n",
        "        prob += pulp.lpDot(G[i].get(), x_vars) <= float(h[i].get()), f\"ineq_{i}\"\n",
        "\n",
        "    # Equality constraints: Ax = b\n",
        "    for i in range(num_eq):\n",
        "        prob += pulp.lpDot(A[i].get(), x_vars) == float(b[i].get()), f\"eq_{i}\"\n",
        "\n",
        "    prob.writeMPS(mps_filename)\n",
        "    print(f\"LP written to: {mps_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d365a35b",
      "metadata": {
        "id": "d365a35b"
      },
      "source": [
        "cplex version (for comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "168f82da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168f82da",
        "outputId": "5c9334c7-86d0-46af-aa80-b6cbb3ce40bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected objective sense:  MINIMIZE\n",
            "Selected objective  name:  OBJ\n",
            "Selected RHS        name:  RHS\n",
            "Selected bound      name:  BND\n",
            "\n",
            "Selected objective sense:  MINIMIZE\n",
            "Selected objective  name:  OBJ\n",
            "Selected RHS        name:  RHS\n",
            "Selected bound      name:  BND\n",
            "Version identifier: 22.1.2.0 | 2024-12-10 | f4cec290b\n",
            "CPXPARAM_Read_DataCheck                          1\n",
            "Tried aggregator 1 time.\n",
            "Linear dependency checker was stopped due to maximum work limit.\n",
            "No LP presolve or aggregator reductions.\n",
            "Presolve time = 0.05 sec. (88.64 ticks)\n",
            "\n",
            "Iteration log . . .\n",
            "Iteration:     1   Dual objective     =         -2351.676780\n",
            "Iteration:    62   Dual objective     =         -1995.690468\n",
            "Iteration:   124   Dual objective     =         -1921.555387\n",
            "Iteration:   186   Dual objective     =         -1842.366068\n",
            "Iteration:   248   Dual objective     =         -1784.710120\n",
            "Iteration:   310   Dual objective     =         -1728.055604\n",
            "Iteration:   372   Dual objective     =         -1682.150353\n",
            "Iteration:   434   Dual objective     =         -1634.366745\n",
            "Iteration:   496   Dual objective     =         -1575.924660\n",
            "Iteration:   562   Dual objective     =         -1514.312681\n",
            "Iteration:   636   Dual objective     =         -1466.989144\n",
            "Iteration:   721   Dual objective     =         -1419.958313\n",
            "Iteration:   807   Dual objective     =         -1366.909469\n",
            "Iteration:   901   Dual objective     =         -1318.451602\n",
            "Iteration:   986   Dual objective     =         -1274.172147\n",
            "Iteration:  1083   Dual objective     =         -1230.946972\n",
            "Iteration:  1195   Dual objective     =         -1189.230717\n",
            "Iteration:  1307   Dual objective     =         -1164.226261\n",
            "Iteration:  1426   Dual objective     =         -1129.442192\n",
            "Iteration:  1539   Dual objective     =         -1093.110712\n",
            "Iteration:  1661   Dual objective     =         -1069.067542\n",
            "Iteration:  1794   Dual objective     =         -1050.754134\n",
            "Iteration:  1917   Dual objective     =         -1039.441369\n",
            "Iteration:  2054   Dual objective     =         -1028.762666\n",
            "Iteration:  2203   Dual objective     =         -1021.843205\n",
            "Iteration:  2353   Dual objective     =         -1016.375277\n",
            "Elapsed time: 2.888499 seconds\n",
            "Objective value: -1015.6014435946518\n"
          ]
        }
      ],
      "source": [
        "import cplex\n",
        "\n",
        "# Solve the LP using either primal simplex, dual simplex, or barrier (interior point).\n",
        "# Only works for LP with no more than 1000 constraints and no more than 1000 variables\n",
        "cpx = cplex.Cplex(\"large_example.mps\")\n",
        "c, G, h, A, b, l, u = mps_to_standard_form(\"large_example.mps\")\n",
        "\n",
        "# Times how long it takes to solve\n",
        "with Timer():\n",
        "    cpx.solve()\n",
        "\n",
        "# Save the minimizer and minimal objective values for comparison\n",
        "cpx_obj_val = cpx.solution.get_objective_value()\n",
        "cpx_min = cpx.solution.get_values()\n",
        "print(\"Objective value:\", cpx_obj_val)\n",
        "#print(\"Minimizer: xᵀ =\", cpx_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27f336d",
      "metadata": {
        "id": "f27f336d"
      },
      "source": [
        "Our PDHG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "d1f0b3d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1f0b3d7",
        "outputId": "d7cf7221-19e5-4cbc-9542-bac31e26c6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected objective sense:  MINIMIZE\n",
            "Selected objective  name:  OBJ\n",
            "Selected RHS        name:  RHS\n",
            "Selected bound      name:  BND\n",
            "0.8688290129274907 0.0 787.3007486389383\n",
            "0.1868538872195678 0.0 801.0467273113345\n",
            "0.11820840256056167 0.0 784.6623112192381\n",
            "0.08894155392875758 0.0 749.9930547787772\n",
            "0.058686442501278996 0.0 714.784626192622\n",
            "0.04450081953254877 0.0 694.3810662526578\n",
            "0.04011934975982188 0.0 756.1190196838978\n",
            "0.03201496475974411 0.0 700.975470564488\n",
            "0.028590343309746462 0.0 725.9857639753775\n",
            "0.022016763381902924 0.0 710.1692455634127\n",
            "0.01674598633624759 0.0 760.8010993792406\n",
            "0.015964601165610236 0.0 708.9457591163577\n",
            "0.01115776533571994 0.0 690.3273027292029\n",
            "0.00855264936821312 0.0 706.7150676835178\n",
            "0.0070803489883533985 0.0 697.2695161981705\n",
            "0.00795383237959395 0.0 712.8734075020873\n",
            "0.008208847091781773 0.0 679.8638413352389\n",
            "0.006707775908358682 0.0 693.9760154728851\n",
            "0.0062525194608344945 0.0 684.9623947971033\n",
            "0.0070676400669694266 0.0 704.6731453759451\n",
            "0.006539018645898381 0.0 707.3244586829188\n",
            "0.006334922353837028 0.0 687.826837705155\n",
            "0.005531957972687933 0.0 705.309654086846\n",
            "0.005157392715876818 0.0 693.7818935798333\n",
            "0.004795748423931136 0.0 701.9082560702379\n",
            "0.00433744141796984 0.0 712.5345538067484\n",
            "0.003536624751471804 0.0 692.7921755894326\n",
            "0.003795319471445452 0.0 705.6665361910599\n",
            "0.0035059145281730723 0.0 709.8404209624141\n",
            "0.0031979161772704213 0.0 708.0414327451394\n",
            "0.0030828100423838365 0.0 708.4194833811102\n",
            "0.002991647781769196 0.0 700.6376273021235\n",
            "0.0026261643859030537 0.0 701.511558235796\n",
            "0.002492892562499532 0.0 694.8505980286446\n",
            "0.0026632985771789515 0.0 700.7987914776918\n",
            "0.0021806804844219626 0.0 699.778014266385\n",
            "0.002522980419782197 0.0 700.9191007815466\n",
            "0.0023994515782132333 0.0 705.5255256696087\n",
            "0.0020830104356834643 0.0 709.8717946711597\n",
            "0.0017167675541652232 0.0 700.8529458484543\n",
            "0.0017699890227772387 0.0 710.6620920403823\n",
            "0.001972083905760114 0.0 702.8609172685094\n",
            "0.0017147153092314847 0.0 705.6583358976085\n",
            "0.0015796932192175485 0.0 706.9758449333274\n",
            "0.0016698413990576656 0.0 704.1595405964912\n",
            "0.0013960885399658795 0.0 704.8471792558845\n",
            "0.0014075263539710793 0.0 706.2563637042499\n",
            "0.0013140427482246058 0.0 710.5747519369702\n",
            "0.0015502609079365048 0.0 705.3788181751013\n",
            "0.0015093194475972905 0.0 703.3882469069849\n",
            "0.0015961378199272523 0.0 700.9022477762969\n",
            "0.0011796888880916457 0.0 706.2067124962364\n",
            "0.0013475997155181724 0.0 700.4827413450404\n",
            "0.0012111033401686387 0.0 701.9112921039266\n",
            "0.001064504772378025 0.0 701.0805211884808\n",
            "0.0011674445916612399 0.0 704.7189261951622\n",
            "0.0012760291646422763 0.0 707.9077868987282\n",
            "0.0010609741467476471 0.0 712.3924041461711\n",
            "0.001294967480409175 0.0 709.6699798149689\n",
            "0.0011832108546918332 0.0 713.310748555658\n",
            "0.0011198450862611178 0.0 710.788656588902\n",
            "0.0012267115363736826 0.0 712.5245123814996\n",
            "0.001035256299197944 0.0 709.6244609708664\n",
            "0.0011403670165704752 0.0 708.1707232169513\n",
            "0.0012037278763220038 0.0 712.6938037994598\n",
            "0.0012182470823427346 0.0 712.1135799827616\n",
            "0.0008484361751540859 0.0 705.5599288840426\n",
            "0.0012510032434469253 0.0 714.2126267577758\n",
            "0.000955434986625072 0.0 721.4974934465613\n",
            "0.0010982028288109426 0.0 717.8989991408224\n",
            "0.0009701671527329654 0.0 717.1423791688538\n",
            "0.0009232538072375499 0.0 722.0373101520523\n",
            "0.001068224065247844 0.0 719.0518702930925\n",
            "0.0009526693764689586 0.0 713.2744680741025\n",
            "0.0010049678379577746 0.0 718.1291674039443\n",
            "0.0007952052627386661 0.0 714.8633610461225\n",
            "0.0008398522699998323 0.0 715.8417883086851\n",
            "0.000922236879696981 0.0 714.9243167677677\n",
            "0.0007801345448165881 0.0 713.0001445147445\n",
            "0.0007867637785806818 0.0 714.9404173700216\n",
            "0.000745655225995094 0.0 710.502172214941\n",
            "0.0007806317666118046 0.0 713.8404061772308\n",
            "0.0007611077589477934 0.0 711.1497523675055\n",
            "0.0007503948229795993 0.0 711.4411756767256\n",
            "0.0007285726690454319 0.0 715.0316212157692\n",
            "0.000754759047226992 0.0 713.9231303912447\n",
            "0.000717608176279714 0.0 713.8474556330325\n",
            "0.0006258349463799799 0.0 715.384119509362\n",
            "0.0005909366493915342 0.0 712.9394790208146\n",
            "0.0005654455274887738 0.0 716.1333722375823\n",
            "0.0005380160493065252 0.0 712.5476790580134\n",
            "0.0005850025816289343 0.0 715.3277294830755\n",
            "0.0005604648651738012 0.0 712.440660493482\n",
            "0.0005303091684406153 0.0 714.4292776938851\n",
            "0.0005423277122933978 0.0 715.9278858542212\n",
            "0.0005714579400456708 0.0 715.1535302508822\n",
            "0.000556604400149548 0.0 713.2698873048697\n",
            "0.0005121418490630317 0.0 715.1042524770397\n",
            "0.0005108241940751291 0.0 713.4485988722446\n",
            "0.0004765938580680434 0.0 715.296567836419\n",
            "0.00043893989310842685 0.0 713.9835811575294\n",
            "0.000467070120811952 0.0 713.9568644466901\n",
            "0.0004730422229736986 0.0 714.8258263602115\n",
            "0.00042042486912001605 0.0 713.9504762053008\n",
            "0.00036873863467901016 0.0 715.9720433303708\n",
            "0.0004632605155318377 0.0 714.1927769362455\n",
            "0.00047215780469486826 0.0 714.9088321735205\n",
            "0.0003888079755552252 0.0 715.617290503149\n",
            "0.00042493112662476344 0.0 713.986429579877\n",
            "0.000418477704551317 0.0 714.4664158014326\n",
            "0.00041172741005656815 0.0 714.4797543281884\n",
            "0.0003607646095996295 0.0 713.3049585607714\n",
            "0.0003457373583507669 0.0 714.2109763616436\n",
            "0.00034900135562197494 0.0 713.3384973128382\n",
            "0.0002992319352465348 0.0 715.23869664003\n",
            "0.00029487671472466 0.0 714.2451314785814\n",
            "0.00038768133740127116 0.0 714.464989492414\n",
            "0.000350241241176586 0.0 714.417095206765\n",
            "0.00026429103328636145 0.0 712.7434513129252\n",
            "0.0003763024713508251 0.0 714.1670857604622\n",
            "0.0003893391711122229 0.0 715.0641749202487\n",
            "0.00034799814288342 0.0 713.5424694622986\n",
            "0.00032383991272904396 0.0 714.8101637986499\n",
            "0.00032769126266919327 0.0 713.3492409487252\n",
            "0.00033786107936213965 0.0 714.6536710424543\n",
            "0.00027738546547858634 0.0 713.9391970728187\n",
            "0.0003059499072207435 0.0 713.9695965852032\n",
            "0.0003401589517136586 0.0 713.7285500760358\n",
            "0.00029140842352483304 0.0 712.6568121848667\n",
            "0.00025407314273251857 0.0 714.5244906807704\n",
            "0.0003625652417413699 0.0 714.640840208674\n",
            "0.00035033953504245687 0.0 713.5940674315416\n",
            "0.00030771669809375157 0.0 714.5579761385175\n",
            "0.00031817333507377053 0.0 714.5573243375279\n",
            "0.00030949288079739793 0.0 714.3736068922112\n",
            "0.0002847277692180383 0.0 715.6230482094\n",
            "0.00024340388864657503 0.0 713.9262277211571\n",
            "0.0002907689141788909 0.0 714.5908385652423\n",
            "0.00029353166166147006 0.0 713.4877232076963\n",
            "0.00022310180210900608 0.0 714.6767668678223\n",
            "0.0002349327497799017 0.0 713.7678303972573\n",
            "0.0003402056915473931 0.0 714.3722065780612\n",
            "0.0003098032055834026 0.0 714.8541126685855\n",
            "0.0002853626834333993 0.0 714.24962189439\n",
            "0.00031037691974869405 0.0 713.5300337310593\n",
            "0.000295548359397141 0.0 714.650441939061\n",
            "0.00029295526120749966 0.0 714.1092521234149\n",
            "0.00027525883485880883 0.0 713.8275765592109\n",
            "0.0002527720195436942 0.0 714.7874442570429\n",
            "0.00026473740422149327 0.0 714.1188084410871\n",
            "0.00020225006458274037 0.0 714.6190193034054\n",
            "0.00022840272765944295 0.0 715.5416498047025\n",
            "0.0002945944411273471 0.0 714.4767900851857\n",
            "0.0002587168335001144 0.0 713.3862078606924\n",
            "0.00020685270079829902 0.0 714.3584443800661\n",
            "0.0002711394264718884 0.0 713.1923702152593\n",
            "0.00027282868343166784 0.0 714.608704540691\n",
            "0.00025694378628849073 0.0 714.2267388234593\n",
            "0.0002262049975850804 0.0 713.2970776908588\n",
            "0.0002597525674418062 0.0 714.4102792344534\n",
            "Elapsed time: 64.392819 seconds\n",
            "Objective Value: -1015.600449884561\n",
            "Iterations: 160000\n"
          ]
        }
      ],
      "source": [
        "# Extract LP parameters from generated example\n",
        "with Timer():\n",
        "    c, G, h, A, b, l, u = mps_to_standard_form(\"large_example.mps\")\n",
        "    pdhg_obj_val, pdhg_min, iterations = pdhg(c, G, h, A, b, l, u, max_iter=1000000, tol=1e-4)\n",
        "print(\"Objective Value:\", pdhg_obj_val)\n",
        "print(\"Iterations:\", iterations)\n",
        "#print(\"Minimizer: xᵀ =\",pdhg_min)\n",
        "\n",
        "# The distance between the two minimizer solutions\n",
        "# Should be small but won't be incredibly small since the vectors are high dimensional\n",
        "#distance = cp.linalg.norm(cp.array(pdhg_min) - cp.array(cpx_min))\n",
        "#print(\"Distance:\", distance)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}